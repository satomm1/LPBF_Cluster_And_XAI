{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9c0e3ec3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5e582f13",
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_DIR = '../../../In-situ Meas Data/Build Command Data/XYPT Commands/' # Directory of XYPT files\n",
    "\n",
    "dt = 1E-5 # 10 microseconds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "eb28d75f",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv(DATA_DIR + 'T500_3D_Scan_Strategies_fused_layer0002.csv', header=None, names=['X', 'Y', 'P', 'T', 'deprecated'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "03661e1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "trigger_indx = np.where(np.array(data['T']))[0]\n",
    "X = np.array(data['X'])\n",
    "Y = np.array(data['Y'])\n",
    "P = np.array(data['P'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d378e485",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Speed\n",
    "x_vel = np.zeros(X.shape)\n",
    "x_vel[1:-1] = (X[2:]-X[:-2]) / 2 / dt\n",
    "\n",
    "y_vel = np.zeros(X.shape)\n",
    "y_vel[1:-1] = (Y[2:]-Y[:-2]) / 2 / dt\n",
    "\n",
    "speed = np.sqrt(np.square(x_vel) + np.square(y_vel))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4c29bfb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Direction\n",
    "vel_dir_x = x_vel / (speed + 1e-8)\n",
    "vel_dir_y = y_vel / (speed + 1e-8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6ff69207",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Acceleration\n",
    "x_accel = np.zeros(X.shape)\n",
    "x_accel[1:-1] = (x_vel[2:]-x_vel[:-2]) / 2 / dt\n",
    "\n",
    "y_accel = np.zeros(Y.shape)\n",
    "y_accel[1:-1] = (y_vel[2:]-y_vel[:-2]) / 2 / dt\n",
    "\n",
    "accel = np.sqrt(np.square(x_accel) + np.square(y_accel))\n",
    "accel[np.where(speed[1:] < speed[:-1])[0]+1] = accel[np.where(speed[1:] < speed[:-1])[0]+1]*-1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "8e5b424c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Energy Density\n",
    "en_den = P / (speed + 1e-8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d2a11f1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Heating/Cooling\n",
    "heating = np.zeros(X.shape)\n",
    "heating[np.where(P[1:]>P[:-1])[0]+1] = 1\n",
    "heating[np.where(P[1:]<P[:-1])[0]+1] = -1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "id": "0f5d731f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, ..., 0, 0, 1])"
      ]
     },
     "execution_count": 126,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Turning\n",
    "turn_threshold = 0.01 # Tune me\n",
    "\n",
    "turning = np.zeros(X.shape)\n",
    "turn1 = np.zeros(X.shape)\n",
    "turn2 = np.zeros(X.shape)\n",
    "\n",
    "turn1[1:] = np.abs(vel_dir_x[1:]-vel_dir_x[:-1])\n",
    "turn2[1:] = np.abs(vel_dir_y[1:]-vel_dir_y[:-1])\n",
    "turning = np.any([(turn1 > turn_threshold), (turn2 > turn_threshold)], axis=0)\n",
    "turning = turning.astype('int')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "8b41f68f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████| 2927/2927 [00:37<00:00, 79.06it/s]\n"
     ]
    }
   ],
   "source": [
    "# Residual Heat\n",
    "R = 10 # parts are 10 mm x 10 mm\n",
    "T = 5\n",
    "max_iters = round(T/dt)\n",
    "\n",
    "residual_heat = np.zeros(X.shape[0])\n",
    "for i in tqdm(trigger_indx):\n",
    "    d_ij = np.sqrt(np.square(X[i]-X[max(0, i-max_iters):i]) + np.square(Y[i]-Y[max(0, i-max_iters):i]))\n",
    "    t_ij = np.linspace((min(max_iters, i))*dt, dt, min(max_iters, i))\n",
    "    p_j = P[max(0, i-max_iters):i]\n",
    "    residual_heat[i] += np.sum(np.square((R-d_ij)/R) * ((T-t_ij)/T) * p_j)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "id": "fca8d06c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merge together, normalize, and save to an excel file\n",
    "P_trig = P[trigger_indx]\n",
    "speed_trig = speed[trigger_indx]\n",
    "x_dir_trig = vel_dir_x[trigger_indx]\n",
    "y_dir_trig = vel_dir_y[trigger_indx]\n",
    "accel_trig = accel[trigger_indx]\n",
    "en_den_trig = en_den[trigger_indx]\n",
    "heating_trig = heating[trigger_indx]\n",
    "turning_trig = turning[trigger_indx]\n",
    "residual_heat_trig = residual_heat[trigger_indx]\n",
    "\n",
    "pp = pd.DataFrame({'P': P_trig, 'speed': speed_trig, 'x_dir': x_dir_trig, 'y_dir': y_dir_trig, 'accel': accel_trig,\n",
    "                  'ed': en_den_trig, 'heating': heating_trig, 'turning': turning_trig, 'res_heat': residual_heat_trig})\n",
    "\n",
    "\n",
    "\n",
    "# pp_normalized = pd.DataFrame()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3342c49",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merge with the labels excel files\n",
    "label = pd.read_excel()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3720ab21",
   "metadata": {},
   "source": [
    "### Now cycle through each layer "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "106e0d34",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████| 249/249 [6:22:35<00:00, 92.19s/it]\n"
     ]
    }
   ],
   "source": [
    "for ii in tqdm(range(2,251)):\n",
    "    if ii < 10:\n",
    "        layer_text = 'layer000' + str(ii)\n",
    "    elif ii < 100:\n",
    "        layer_text = 'layer00' + str(ii)\n",
    "    else:\n",
    "        layer_text = 'layer0' + str(ii)\n",
    "        \n",
    "    data = pd.read_csv(DATA_DIR + 'T500_3D_Scan_Strategies_fused_' + layer_text + '.csv', header=None, \n",
    "                       names=['X', 'Y', 'P', 'T', 'deprecated'])\n",
    "    \n",
    "    trigger_indx = np.where(np.array(data['T']))[0]\n",
    "    X = np.array(data['X'])\n",
    "    Y = np.array(data['Y'])\n",
    "    P = np.array(data['P'])\n",
    "    \n",
    "    # Speed\n",
    "    x_vel = np.zeros(X.shape)\n",
    "    x_vel[1:-1] = (X[2:]-X[:-2]) / 2 / dt\n",
    "\n",
    "    y_vel = np.zeros(X.shape)\n",
    "    y_vel[1:-1] = (Y[2:]-Y[:-2]) / 2 / dt\n",
    "\n",
    "    speed = np.sqrt(np.square(x_vel) + np.square(y_vel))\n",
    "    \n",
    "    # Direction\n",
    "    vel_dir_x = x_vel / (speed + 1e-8)\n",
    "    vel_dir_y = y_vel / (speed + 1e-8)\n",
    "    \n",
    "    # Acceleration\n",
    "    x_accel = np.zeros(X.shape)\n",
    "    x_accel[1:-1] = (x_vel[2:]-x_vel[:-2]) / 2 / dt\n",
    "\n",
    "    y_accel = np.zeros(Y.shape)\n",
    "    y_accel[1:-1] = (y_vel[2:]-y_vel[:-2]) / 2 / dt\n",
    "\n",
    "    accel = np.sqrt(np.square(x_accel) + np.square(y_accel))\n",
    "    accel[np.where(speed[1:] < speed[:-1])[0]+1] = accel[np.where(speed[1:] < speed[:-1])[0]+1]*-1\n",
    "    \n",
    "    # Energy Density\n",
    "    en_den = P / (speed + 1e-8)\n",
    "    \n",
    "    # Heating/Cooling\n",
    "    heating = np.zeros(X.shape)\n",
    "    heating[np.where(P[1:]>P[:-1])[0]+1] = 1\n",
    "    heating[np.where(P[1:]<P[:-1])[0]+1] = -1\n",
    "    \n",
    "    # Turning\n",
    "    turn_threshold = 0.01 # Tune me\n",
    "\n",
    "    turning = np.zeros(X.shape)\n",
    "    turn1 = np.zeros(X.shape)\n",
    "    turn2 = np.zeros(X.shape)\n",
    "\n",
    "    turn1[1:] = np.abs(vel_dir_x[1:]-vel_dir_x[:-1])\n",
    "    turn2[1:] = np.abs(vel_dir_y[1:]-vel_dir_y[:-1])\n",
    "    turning = np.any([(turn1 > turn_threshold), (turn2 > turn_threshold)], axis=0)\n",
    "    turning = turning.astype('int')\n",
    "    \n",
    "    # Residual Heat\n",
    "    R = 10 # parts are 10 mm x 10 mm\n",
    "    T = 5\n",
    "    max_iters = round(T/dt)\n",
    "\n",
    "    residual_heat = np.zeros(X.shape[0])\n",
    "    for i in trigger_indx:\n",
    "        d_ij = np.sqrt(np.square(X[i]-X[max(0, i-max_iters):i]) + np.square(Y[i]-Y[max(0, i-max_iters):i]))\n",
    "        t_ij = np.linspace((min(max_iters, i))*dt, dt, min(max_iters, i))\n",
    "        p_j = P[max(0, i-max_iters):i]\n",
    "        residual_heat[i] += np.sum(np.square((R-d_ij)/R) * ((T-t_ij)/T) * p_j)\n",
    "        \n",
    "    P_trig = P[trigger_indx]\n",
    "    speed_trig = speed[trigger_indx]\n",
    "    x_dir_trig = vel_dir_x[trigger_indx]\n",
    "    y_dir_trig = vel_dir_y[trigger_indx]\n",
    "    accel_trig = accel[trigger_indx]\n",
    "    en_den_trig = en_den[trigger_indx]\n",
    "    heating_trig = heating[trigger_indx]\n",
    "    turning_trig = turning[trigger_indx]\n",
    "    residual_heat_trig = residual_heat[trigger_indx]\n",
    "\n",
    "    pp = pd.DataFrame({'P': P_trig, 'speed': speed_trig, 'x_dir': x_dir_trig, 'y_dir': y_dir_trig, 'accel': accel_trig,\n",
    "                      'ed': en_den_trig, 'heating': heating_trig, 'turning': turning_trig, 'res_heat': residual_heat_trig})\n",
    "    \n",
    "    pp.to_excel('process_parameters/by_layer/' + layer_text + '.xlsx',header=False, index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bbad7edc",
   "metadata": {},
   "source": [
    "### Normalize data for mean=0, std=1 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "e5dbf3e1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 249/249 [02:26<00:00,  1.69it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The total number of data points is: 1036741\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Get total number of data\n",
    "num_data = 0\n",
    "for ii in tqdm(range(2,251)):\n",
    "    \n",
    "    if ii < 10:\n",
    "        layer_text = 'layer000' + str(ii)\n",
    "    elif ii < 100:\n",
    "        layer_text = 'layer00' + str(ii)\n",
    "    else:\n",
    "        layer_text = 'layer0' + str(ii)\n",
    "    \n",
    "    pp = pd.read_excel('process_parameters/by_layer/' + layer_text + '.xlsx', header=None)\n",
    "    num_data += pp[0].shape[0]\n",
    "    \n",
    "print(\"The total number of data points is: \" + str(num_data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "47a6f0b0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 249/249 [02:23<00:00,  1.74it/s]\n"
     ]
    }
   ],
   "source": [
    "P_total        = np.zeros((num_data,1))\n",
    "speed_total    = np.zeros((num_data,1))\n",
    "x_dir_total    = np.zeros((num_data,1))\n",
    "y_dir_total    = np.zeros((num_data,1))\n",
    "accel_total    = np.zeros((num_data,1))\n",
    "ed_total       = np.zeros((num_data,1))\n",
    "heating_total  = np.zeros((num_data,1))\n",
    "turning_total  = np.zeros((num_data,1))\n",
    "res_heat_total = np.zeros((num_data,1))\n",
    "\n",
    "# Now collect all the data\n",
    "indx = 0\n",
    "for ii in tqdm(range(2,251)):\n",
    "    \n",
    "    if ii < 10:\n",
    "        layer_text = 'layer000' + str(ii)\n",
    "    elif ii < 100:\n",
    "        layer_text = 'layer00' + str(ii)\n",
    "    else:\n",
    "        layer_text = 'layer0' + str(ii)\n",
    "    \n",
    "    pp = pd.read_excel('process_parameters/by_layer/' + layer_text + '.xlsx', header=None)\n",
    "    \n",
    "    data_in_layer = pp[0].shape[0]\n",
    "    \n",
    "    P = np.array(pp[0])\n",
    "    speed = np.array(pp[1])\n",
    "    x_dir = np.array(pp[2])\n",
    "    y_dir = np.array(pp[3])\n",
    "    accel = np.array(pp[4])\n",
    "    ed = np.array(pp[5])\n",
    "    heating = np.array(pp[6])\n",
    "    turning = np.array(pp[7])\n",
    "    res_heat = np.array(pp[8])\n",
    "    \n",
    "    new_indx = indx+data_in_layer\n",
    "    \n",
    "    P_total[indx:new_indx,0]        = P\n",
    "    speed_total[indx:new_indx,0]    = speed\n",
    "    x_dir_total[indx:new_indx,0]    = x_dir\n",
    "    y_dir_total[indx:new_indx,0]    = y_dir\n",
    "    accel_total[indx:new_indx,0]    = accel\n",
    "    ed_total[indx:new_indx,0]       = ed\n",
    "    heating_total[indx:new_indx,0]  = heating\n",
    "    turning_total[indx:new_indx,0]  = turning\n",
    "    res_heat_total[indx:new_indx,0] = res_heat\n",
    "    \n",
    "    indx = new_indx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "906f65ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get normalizing coefficients\n",
    "pp_mean = dict()\n",
    "pp_std = dict()\n",
    "\n",
    "pp_mean['P']        = np.mean(P_total)\n",
    "pp_mean['speed']    = np.mean(speed_total)\n",
    "pp_mean['x_dir']    = np.mean(x_dir_total)\n",
    "pp_mean['y_dir']    = np.mean(y_dir_total)\n",
    "pp_mean['accel']    = np.mean(accel_total)\n",
    "pp_mean['ed']       = np.mean(ed_total)\n",
    "pp_mean['heating']  = np.mean(heating_total)\n",
    "pp_mean['turning']  = np.mean(turning_total)\n",
    "pp_mean['res_heat'] = np.mean(res_heat_total)\n",
    "\n",
    "pp_std['P']        = np.std(P_total)\n",
    "pp_std['speed']    = np.std(speed_total)\n",
    "pp_std['x_dir']    = np.std(x_dir_total)\n",
    "pp_std['y_dir']    = np.std(y_dir_total)\n",
    "pp_std['accel']    = np.std(accel_total)\n",
    "pp_std['ed']       = np.std(ed_total)\n",
    "pp_std['heating']  = np.std(heating_total)\n",
    "pp_std['turning']  = np.std(turning_total)\n",
    "pp_std['res_heat'] = np.std(res_heat_total)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "c145c27f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normalize the data\n",
    "P_norm        = np.squeeze((P_total - pp_mean['P']) / pp_std['P'])\n",
    "speed_norm    = np.squeeze((speed_total - pp_mean['speed']) / pp_std['speed'])\n",
    "x_dir_norm    = np.squeeze((x_dir_total - pp_mean['x_dir']) / pp_std['x_dir'])\n",
    "y_dir_norm    = np.squeeze((y_dir_total - pp_mean['y_dir']) / pp_std['y_dir'])\n",
    "accel_norm    = np.squeeze((accel_total - pp_mean['accel']) / pp_std['accel'])\n",
    "ed_norm       = np.squeeze((ed_total - pp_mean['ed']) / pp_std['ed'])\n",
    "heating_norm  = np.squeeze(heating_total) # boolean values\n",
    "turning_norm  = np.squeeze(turning_total) # boolean values\n",
    "res_heat_norm = np.squeeze((res_heat_total - pp_mean['res_heat']) / pp_std['res_heat'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "ed51b0d9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 249/249 [02:38<00:00,  1.57it/s]\n"
     ]
    }
   ],
   "source": [
    "image_name = list()\n",
    "for ii in tqdm(range(2,251)):\n",
    "    if ii < 10:\n",
    "        layer_text = 'layer000' + str(ii)\n",
    "    elif ii < 100:\n",
    "        layer_text = 'layer00' + str(ii)\n",
    "    else:\n",
    "        layer_text = 'layer0' + str(ii)\n",
    "        \n",
    "    pp = pd.read_excel('process_parameters/by_layer/' + layer_text + '.xlsx', header=None)\n",
    "    data_in_layer = pp[0].shape[0]\n",
    "    \n",
    "    for image_num in range(data_in_layer):\n",
    "        image_name.append('layer' + str(ii) + '_' + str(image_num+1) + '.png')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "55abe62e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the normalized process parameters to a spreadsheet\n",
    "pp_norm = pd.DataFrame({'P': P_norm, 'speed': speed_norm, 'x_dir': x_dir_norm, 'y_dir': y_dir_norm, 'accel': accel_norm,\n",
    "                      'ed': ed_norm, 'heating': heating_norm, 'turning': turning_norm, 'res_heat': res_heat_norm,\n",
    "                       'image_name': np.array(image_name)})\n",
    "pp_norm.to_excel('process_parameters/normalized_pp.xlsx',header=False, index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "481432d9",
   "metadata": {},
   "source": [
    "### Create a unified spreadsheet holding image name, labels, and process parameters "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4dbdae69",
   "metadata": {},
   "outputs": [],
   "source": [
    "pp_norm = pd.read_excel('process_parameters/normalized_pp.xlsx', header=None)\n",
    "train_labels = pd.read_excel('neural_network_data/train_labels.xlsx', header=None)\n",
    "dev_labels = pd.read_excel('neural_network_data/dev_labels.xlsx', header=None)\n",
    "test_labels = pd.read_excel('neural_network_data/test_labels.xlsx', header=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f0cdc8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "image_dir = '../../../In-situ Meas Data/In-situ Meas Data/Melt Pool Camera Preprocessed PNG/'\n",
    "\n",
    "image_name_list = np.array(pp_norm[9])\n",
    "\n",
    "# Train set\n",
    "P_train        = list()\n",
    "speed_train    = list()\n",
    "x_dir_train    = list()\n",
    "y_dir_train    = list()\n",
    "accel_train    = list()\n",
    "ed_train       = list()\n",
    "heating_train  = list()\n",
    "turning_train  = list()\n",
    "res_heat_train = list()\n",
    "image_name_train = list()\n",
    "label_train = list()\n",
    "\n",
    "for ii in tqdm(range(train_labels[0].shape[0])):\n",
    "    image_loc = train_labels[0][ii]\n",
    "    image_name_start = image_loc.find('layer', 80)\n",
    "    if image_name_start == -1:\n",
    "        raise Exception(\"Couldn't find image name\")\n",
    "        \n",
    "    image_name = image_loc[image_name_start:]\n",
    "    \n",
    "    underscore = image_name.find('_')\n",
    "    layer_number = int(image_name[5:underscore])\n",
    "    \n",
    "    if layer_number != 1 and layer_number != 5: # we do not have the data for layer1 and layer5 for some reason\n",
    "        image_name_indx = np.where(image_name_list == image_name)[0][0]\n",
    "        \n",
    "        P_train.append(pp_norm[0][image_name_indx])\n",
    "        speed_train.append(pp_norm[1][image_name_indx])\n",
    "        x_dir_train.append(pp_norm[2][image_name_indx])\n",
    "        y_dir_train.append(pp_norm[3][image_name_indx])\n",
    "        accel_train.append(pp_norm[4][image_name_indx])\n",
    "        ed_train.append(pp_norm[5][image_name_indx])\n",
    "        heating_train.append(pp_norm[6][image_name_indx])\n",
    "        turning_train.append(pp_norm[7][image_name_indx])\n",
    "        res_heat_train.append(pp_norm[8][image_name_indx])\n",
    "        image_name_train.append(image_name)\n",
    "        label_train.append(train_labels[1][ii])\n",
    "\n",
    "train_labels_pp = pd.DataFrame({'image_name': np.array(image_name_train), 'label': np.array(label_train),\n",
    "                               'P': np.array(P_train), 'speed': np.array(speed_train), 'x_dir': np.array(x_dir_train), \n",
    "                               'y_dir': np.array(y_dir_train), 'accel': np.array(accel_train), 'ed': np.array(ed_train), \n",
    "                               'heating': np.array(heating_train), 'turning': np.array(turning_train), \n",
    "                               'res_heat': np.array(res_heat_train)})\n",
    "                                     \n",
    "train_labels_pp.to_excel('neural_network_data/train_labels_pp.xlsx',header=True, index=False)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "545f7067",
   "metadata": {},
   "outputs": [],
   "source": [
    "# dev set\n",
    "P_dev        = list()\n",
    "speed_dev    = list()\n",
    "x_dir_dev    = list()\n",
    "y_dir_dev    = list()\n",
    "accel_dev    = list()\n",
    "ed_dev       = list()\n",
    "heating_dev  = list()\n",
    "turning_dev  = list()\n",
    "res_heat_dev = list()\n",
    "image_name_dev = list()\n",
    "label_dev = list()\n",
    "\n",
    "for ii in tqdm(range(dev_labels[0].shape[0])):\n",
    "    image_loc = dev_labels[0][ii]\n",
    "    image_name_start = image_loc.find('layer', 80)\n",
    "    if image_name_start == -1:\n",
    "        raise Exception(\"Couldn't find image name\")\n",
    "        \n",
    "    image_name = image_loc[image_name_start:]\n",
    "    \n",
    "    underscore = image_name.find('_')\n",
    "    layer_number = int(image_name[5:underscore])\n",
    "    \n",
    "    if layer_number != 1 and layer_number != 5: # we do not have the data for layer1 and layer5 for some reason\n",
    "        image_name_indx = np.where(image_name_list == image_name)[0][0]\n",
    "        \n",
    "        P_dev.append(pp_norm[0][image_name_indx])\n",
    "        speed_dev.append(pp_norm[1][image_name_indx])\n",
    "        x_dir_dev.append(pp_norm[2][image_name_indx])\n",
    "        y_dir_dev.append(pp_norm[3][image_name_indx])\n",
    "        accel_dev.append(pp_norm[4][image_name_indx])\n",
    "        ed_dev.append(pp_norm[5][image_name_indx])\n",
    "        heating_dev.append(pp_norm[6][image_name_indx])\n",
    "        turning_dev.append(pp_norm[7][image_name_indx])\n",
    "        res_heat_dev.append(pp_norm[8][image_name_indx])\n",
    "        image_name_dev.append(image_name)\n",
    "        label_dev.append(dev_labels[1][ii])\n",
    "\n",
    "dev_labels_pp = pd.DataFrame({'image_name': np.array(image_name_dev), 'label': np.array(label_dev),\n",
    "                               'P': np.array(P_dev), 'speed': np.array(speed_dev), 'x_dir': np.array(x_dir_dev), \n",
    "                               'y_dir': np.array(y_dir_dev), 'accel': np.array(accel_dev), 'ed': np.array(ed_dev), \n",
    "                               'heating': np.array(heating_dev), 'turning': np.array(turning_dev), \n",
    "                               'res_heat': np.array(res_heat_dev)})\n",
    "                                     \n",
    "dev_labels_pp.to_excel('neural_network_data/dev_labels_pp.xlsx',header=True, index=False)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b976476c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# test set\n",
    "P_test        = list()\n",
    "speed_test    = list()\n",
    "x_dir_test    = list()\n",
    "y_dir_test    = list()\n",
    "accel_test    = list()\n",
    "ed_test       = list()\n",
    "heating_test  = list()\n",
    "turning_test  = list()\n",
    "res_heat_test = list()\n",
    "image_name_test = list()\n",
    "label_test = list()\n",
    "\n",
    "for ii in tqdm(range(test_labels[0].shape[0])):\n",
    "    image_loc = test_labels[0][ii]\n",
    "    image_name_start = image_loc.find('layer', 80)\n",
    "    if image_name_start == -1:\n",
    "        raise Exception(\"Couldn't find image name\")\n",
    "        \n",
    "    image_name = image_loc[image_name_start:]\n",
    "    \n",
    "    underscore = image_name.find('_')\n",
    "    layer_number = int(image_name[5:underscore])\n",
    "    \n",
    "    if layer_number != 1 and layer_number != 5: # we do not have the data for layer1 and layer5 for some reason\n",
    "        image_name_indx = np.where(image_name_list == image_name)[0][0]\n",
    "        \n",
    "        P_test.append(pp_norm[0][image_name_indx])\n",
    "        speed_test.append(pp_norm[1][image_name_indx])\n",
    "        x_dir_test.append(pp_norm[2][image_name_indx])\n",
    "        y_dir_test.append(pp_norm[3][image_name_indx])\n",
    "        accel_test.append(pp_norm[4][image_name_indx])\n",
    "        ed_test.append(pp_norm[5][image_name_indx])\n",
    "        heating_test.append(pp_norm[6][image_name_indx])\n",
    "        turning_test.append(pp_norm[7][image_name_indx])\n",
    "        res_heat_test.append(pp_norm[8][image_name_indx])\n",
    "        image_name_test.append(image_name)\n",
    "        label_test.append(test_labels[1][ii])\n",
    "\n",
    "test_labels_pp = pd.DataFrame({'image_name': np.array(image_name_test), 'label': np.array(label_test),\n",
    "                               'P': np.array(P_test), 'speed': np.array(speed_test), 'x_dir': np.array(x_dir_test), \n",
    "                               'y_dir': np.array(y_dir_test), 'accel': np.array(accel_test), 'ed': np.array(ed_test), \n",
    "                               'heating': np.array(heating_test), 'turning': np.array(turning_test), \n",
    "                               'res_heat': np.array(res_heat_test)})\n",
    "                                     \n",
    "test_labels_pp.to_excel('neural_network_data/test_labels_pp.xlsx',header=True, index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "meltpool_env",
   "language": "python",
   "name": "meltpool_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
