{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Implements Layer-wise Relevance Propagation for the NIST AM dataset\n",
    "#### LRP-epsilon"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import torchvision\n",
    "from torchvision import transforms, datasets\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import os\n",
    "from skimage import io\n",
    "import pandas as pd\n",
    "import copy\n",
    "import cv2\n",
    "from PIL import Image as im\n",
    "from torchvision.models import resnet18\n",
    "import openpyxl\n",
    "from matplotlib.legend_handler import HandlerTuple\n",
    "from tqdm import tqdm\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Include the neural network architecture and dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MeltPoolNetwork(nn.Module):\n",
    "    \"\"\"Neural Network for Melt Pool Shape Prediction\"\"\"\n",
    "    \n",
    "    def __init__(self, imageModel, num_classes=10, num_param=10):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            imageModel (A pytorch model): the CNN to use for melt pool image encoding\n",
    "            num_classes (int): Number of different melt pool classes to predict\n",
    "            num_param (int): Number of process parameters available\n",
    "        \"\"\"\n",
    "        \n",
    "        super().__init__()\n",
    "        # The image encoder CNN\n",
    "        self.ImageModel = imageModel\n",
    "        \n",
    "        # The process parameter encoder layers\n",
    "        self.paramLayer1 = nn.Sequential(nn.Linear(num_param, 10), nn.Tanh())\n",
    "        self.paramLayer2 = nn.Sequential(nn.Linear(10, 10), nn.Tanh())\n",
    "        self.paramLayer3 = nn.Sequential(nn.Linear(10, 10), nn.Tanh())\n",
    "        self.paramLayer4 = nn.Sequential(nn.Linear(10, 10), nn.Tanh())\n",
    "        \n",
    "        # prediction head layers\n",
    "        self.prediction1 = nn.Sequential(nn.Linear(512+10, 100), nn.Tanh())\n",
    "        self.prediction2 = nn.Linear(100, num_classes)\n",
    "#         self.prediction = nn.Linear(512+10, num_classes)\n",
    "\n",
    "        # Initialize Model Weights\n",
    "        tanh_gain = torch.nn.init.calculate_gain('tanh', param=None)\n",
    "        torch.nn.init.xavier_normal_(self.paramLayer1[0].weight, gain=tanh_gain)\n",
    "        torch.nn.init.xavier_normal_(self.paramLayer2[0].weight, gain=tanh_gain)\n",
    "        torch.nn.init.xavier_normal_(self.paramLayer3[0].weight, gain=tanh_gain)\n",
    "        torch.nn.init.xavier_normal_(self.paramLayer4[0].weight, gain=tanh_gain)\n",
    "        torch.nn.init.xavier_normal_(self.prediction1[0].weight, gain=tanh_gain)\n",
    "        torch.nn.init.kaiming_normal_(self.prediction2.weight, a=0, mode='fan_in', nonlinearity='relu')\n",
    "\n",
    "    def forward(self, img, pp):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            img (tensor): The melt pool image\n",
    "            pp  (tensor): The process parameters\n",
    "        \"\"\"\n",
    "        \n",
    "        # Image CNN\n",
    "        x = self.ImageModel(img)\n",
    "\n",
    "        # PP NN\n",
    "        y = self.paramLayer1(pp)\n",
    "        y = self.paramLayer2(y)\n",
    "        y = self.paramLayer3(y)\n",
    "        y = self.paramLayer4(y)\n",
    "        y = y.view(y.size(0), -1)\n",
    "\n",
    "        # Prediction Head\n",
    "#         y = torch.squeeze(y)  # remove any dimensions of 1\n",
    "        z = torch.cat((x, y), dim=1)\n",
    "        z = self.prediction1(z)\n",
    "        z = self.prediction2(z)\n",
    "#         z = self.prediction(z)\n",
    "        return z"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MeltpoolDataset(Dataset):\n",
    "    \"\"\"Dataset for Meltpool Images and Process Parameters\"\"\"\n",
    "\n",
    "    def __init__(self, xlsx_file, root_dir, transform=None):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            xlsx_file (string): file with process parameters and labels\n",
    "            root_dir (string): image directory\n",
    "            transform (callable, optional): transform(s) to apply\n",
    "        \"\"\"\n",
    "\n",
    "        print('************** Loading Data **************')\n",
    "        print(xlsx_file)\n",
    "        \n",
    "        # Load the excel file and separate into image file names, labels, and process parameters\n",
    "        if xlsx_file.find('xlsx') >= 0:\n",
    "            data_frame = pd.read_excel(xlsx_file, sheet_name='Sheet1', engine='openpyxl')\n",
    "        elif xlsx_file.find('csv')>= 0:\n",
    "            data_frame = pd.read_csv(xlsx_file)\n",
    "        self.images = np.array(data_frame['image_name'])\n",
    "        self.labels = np.array(data_frame['label'])\n",
    "        self.process_parameters = np.array(data_frame[data_frame.columns[2:]])\n",
    "\n",
    "        # We need to modify the image file names\n",
    "        for ii in range(self.images.shape[0]):\n",
    "            layer = self.images[ii][0:self.images[ii].find('_')]\n",
    "            self.images[ii] = layer + '/' + self.images[ii]\n",
    "\n",
    "        # Store some important information\n",
    "        self.root_dir = root_dir\n",
    "        self.transform = transform\n",
    "        self.PIL_transform = transforms.ToPILImage()\n",
    "        print('************ Finished Loading ************')\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.images.shape[0]\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        if torch.is_tensor(idx):\n",
    "            idx = idx.tolist()\n",
    "\n",
    "        # Load the image and convert to a PIL image\n",
    "        img_name = os.path.join(self.root_dir, self.images[idx])\n",
    "        image = io.imread(img_name)\n",
    "#         image = self.PIL_transform(image).convert('RGB')\n",
    "        image = self.PIL_transform(image)\n",
    "        \n",
    "        # Apply transforms to the image\n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "        \n",
    "        # Load the process parameters\n",
    "        pp = self.process_parameters[idx, :]\n",
    "        pp = pp.astype('float')\n",
    "        \n",
    "        # Load the label\n",
    "        label = self.labels[idx]        \n",
    "\n",
    "        return {'image': image, 'process_parameters': pp, 'label': label}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LRP-Epsilon"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LRP(nn.Module):\n",
    "\n",
    "    def __init__(self, model, eps=1.0e-9, gamma=0.1):\n",
    "        super().__init__()\n",
    "        self.model = model\n",
    "        self.model.eval()\n",
    "\n",
    "        self.eps = eps\n",
    "        self.gamma = gamma\n",
    "        self.layers = self.get_layers()\n",
    "\n",
    "    def get_layers(self):\n",
    "\n",
    "        # Builds list of all layers in the neural network\n",
    "        # Works specifically for this CNN\n",
    "        img_model_layers = nn.ModuleList()\n",
    "        for module in self.model.ImageModel.children():\n",
    "            if isinstance(module, nn.Sequential):\n",
    "                for module2 in module.children():\n",
    "                    # for module3 in module2.children():\n",
    "                    #     if isinstance(module3, nn.Sequential):\n",
    "                    #         for module4 in module3.children():\n",
    "                    #             layers.append(module4)\n",
    "                    #     else:\n",
    "                    #         layers.append(module3)\n",
    "                    img_model_layers.append(module2)\n",
    "            else:\n",
    "                img_model_layers.append(module)\n",
    "        #         print(layers)\n",
    "\n",
    "        param_layers = nn.ModuleList()\n",
    "        final_layers = nn.ModuleList()\n",
    "        for module in self.model.children():\n",
    "            if not isinstance(module, torchvision.models.resnet.ResNet):\n",
    "                if isinstance(module, nn.Sequential):\n",
    "                    if module[0].in_features < 512:\n",
    "                        for module2 in module.children():\n",
    "                            param_layers.append(module2)\n",
    "                    else:\n",
    "                        for module2 in module.children():\n",
    "                            final_layers.append(module2)\n",
    "                else:\n",
    "                    final_layers.append(module)\n",
    "\n",
    "        layers = {\"image\": img_model_layers, \"pp\": param_layers, \"final\": final_layers}\n",
    "        return layers\n",
    "\n",
    "    def evaluate(self, sample):\n",
    "        img = sample['image']\n",
    "        x = img.to(device=device, dtype=torch.float)\n",
    "        pp = sample['process_parameters']\n",
    "        y = pp.to(device=device, dtype=torch.float)\n",
    "\n",
    "        img_act = []\n",
    "        pp_act = []\n",
    "        final_act = []\n",
    "\n",
    "        with torch.no_grad():\n",
    "            img_act.append(torch.ones_like(x))\n",
    "            for layer in self.layers[\"image\"]:\n",
    "                #                 print(layer)\n",
    "                if isinstance(layer, nn.Linear):\n",
    "                    x = x.squeeze(dim=2)\n",
    "                    x = x.squeeze(dim=2)\n",
    "                x = layer(x)\n",
    "                # print(x.shape)\n",
    "                img_act.append(x)\n",
    "\n",
    "            pp_act.append(torch.ones_like(pp))\n",
    "            for layer in self.layers[\"pp\"]:\n",
    "                y = layer(y)\n",
    "                pp_act.append(y)\n",
    "\n",
    "            # y = y.view(y.size(0), -1)\n",
    "            x = torch.squeeze(x)\n",
    "            y = torch.squeeze(y)\n",
    "            z = torch.cat((x, y), dim=-1)\n",
    "            for layer in self.layers[\"final\"]:\n",
    "                z = layer(z)\n",
    "                final_act.append(z)\n",
    "\n",
    "        img_act = img_act[::-1]  # reverse order\n",
    "        img_act = [a.requires_grad_(True) for a in img_act]\n",
    "\n",
    "        pp_act = pp_act[::-1]\n",
    "        pp_act = [a.requires_grad_(True) for a in pp_act]\n",
    "\n",
    "        final_act = final_act[::-1]\n",
    "        final_act = [a.requires_grad_(True) for a in final_act]\n",
    "\n",
    "        R = torch.softmax(final_act.pop(0), dim=-1)\n",
    "        R_final = R\n",
    "\n",
    "        R_final_list = []\n",
    "        R_final_list.append(R)\n",
    "\n",
    "        img_layers = self.layers['image']\n",
    "        pp_layers = self.layers['pp']\n",
    "        final_layers = self.layers['final']\n",
    "\n",
    "        reverse_img_layers = img_layers[::-1]\n",
    "        reverse_pp_layers = pp_layers[::-1]\n",
    "        reverse_final_layers = final_layers[::-1]\n",
    "\n",
    "        for layer in reverse_final_layers[:-1]:\n",
    "            R_final = self.lrp_eval(layer, final_act.pop(0), R_final)\n",
    "            R_final_list.append(R_final)\n",
    "\n",
    "        act1 = img_act.pop(0)\n",
    "        # act1 = torch.squeeze(act1, dim=0)\n",
    "        act2 = pp_act.pop(0)\n",
    "        # act2 = torch.squeeze(act2, dim=0)\n",
    "        act = torch.cat((act1, act2), dim=1)\n",
    "\n",
    "        R = self.lrp_eval(final_layers[0], act, R_final)\n",
    "        R_final_list.append(R)\n",
    "\n",
    "        R_img = R[0:512]\n",
    "        R_img_list = []\n",
    "        for layer in reverse_img_layers:\n",
    "            R_img = self.lrp_eval(layer, img_act.pop(0), R_img)\n",
    "            R_img_list.append(R_img)\n",
    "\n",
    "        R_pp = R[512:]\n",
    "        R_pp_list = []\n",
    "        for layer in reverse_pp_layers:\n",
    "            R_pp = self.lrp_eval(layer, pp_act.pop(0).to(device=device, dtype=torch.float), R_pp)\n",
    "            R_pp_list.append(R_pp)\n",
    "\n",
    "        return {\"image\": R_img_list, \"pp\": R_pp_list, \"final\": R_final_list}\n",
    "\n",
    "    def lrp_eval(self, layer, a, R):\n",
    "        if isinstance(layer, nn.Linear):\n",
    "            a = a.squeeze()\n",
    "\n",
    "        if isinstance(layer, nn.ReLU):\n",
    "            return R\n",
    "\n",
    "        a = a.data.requires_grad_(True)\n",
    "        z = self.eps + layer.forward(a)\n",
    "        s = (R / (z + 1e-9)).data  # 1e-9 to prevent divide by 0\n",
    "        (z * s).sum().backward()\n",
    "        c = a.grad\n",
    "        R = a * c\n",
    "        return R"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load the data, neural network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 1 # Minibatch size to use\n",
    "NUM_MELT_POOL_CLASSES = 24 # Number of different melt pool shape classes\n",
    "NUM_PROCESS_PARAM = 9 # Number of process parameters\n",
    "EPS = 0.1\n",
    "\n",
    "# The base directory to images\n",
    "# DATA_DIR = '../../../In-situ Meas Data/In-situ Meas Data/Melt Pool Camera Preprocessed PNG/'\n",
    "DATA_DIR = '../../Melt Pool Camera Preprocessed PNG/'\n",
    "# DATA_DIR = '../../RealTimeControl/Preprocessed Images/'\n",
    "\n",
    "MODEL_NAME = 'testV30_1' # Name to save trained model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "************** Loading Data **************\n",
      "neural_network_data/dev_labels_pp_limited_scan_3d.csv\n",
      "************ Finished Loading ************\n"
     ]
    }
   ],
   "source": [
    "# neural_network_data/train_labels_pp.xlsx'\n",
    "# meltpool_dataset_test = MeltpoolDataset(\n",
    "#     'neural_network_data/test_labels_pp.csv', \n",
    "#     DATA_DIR,\n",
    "#     transform=transforms.Compose([\n",
    "#         transforms.Resize(256),\n",
    "#         transforms.CenterCrop(224),\n",
    "#         transforms.ToTensor(),\n",
    "#         transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "#     ])\n",
    "# )\n",
    "meltpool_dataset_test = MeltpoolDataset(\n",
    "    'neural_network_data/dev_labels_pp_limited_scan_3d.csv', \n",
    "    DATA_DIR,\n",
    "    transform=transforms.Compose([\n",
    "        transforms.Resize(256),\n",
    "        transforms.CenterCrop(224),\n",
    "        transforms.ToTensor()\n",
    "    ])\n",
    ")\n",
    "\n",
    "dataloader_test = DataLoader(meltpool_dataset_test, batch_size=BATCH_SIZE, shuffle=True, num_workers=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_iter = iter(dataloader_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'image': tensor([[[[0.0275, 0.0275, 0.0275,  ..., 0.0196, 0.0196, 0.0196],\n",
       "           [0.0235, 0.0235, 0.0235,  ..., 0.0196, 0.0196, 0.0196],\n",
       "           [0.0235, 0.0235, 0.0235,  ..., 0.0196, 0.0196, 0.0196],\n",
       "           ...,\n",
       "           [0.0314, 0.0275, 0.0275,  ..., 0.0235, 0.0275, 0.0275],\n",
       "           [0.0314, 0.0275, 0.0235,  ..., 0.0235, 0.0235, 0.0235],\n",
       "           [0.0314, 0.0275, 0.0235,  ..., 0.0235, 0.0235, 0.0235]]]]),\n",
       " 'process_parameters': tensor([[-0.6453,  0.5981,  0.0186, -0.6481,  0.0000, -0.5242,  0.0000,  1.0000,\n",
       "           0.0000]], dtype=torch.float64),\n",
       " 'label': tensor([20])}"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = next(data_iter)\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MeltPoolNetwork(\n",
       "  (ImageModel): ResNet(\n",
       "    (conv1): Conv2d(1, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
       "    (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (relu): ReLU(inplace=True)\n",
       "    (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
       "    (layer1): Sequential(\n",
       "      (0): BasicBlock(\n",
       "        (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (1): BasicBlock(\n",
       "        (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (layer2): Sequential(\n",
       "      (0): BasicBlock(\n",
       "        (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (downsample): Sequential(\n",
       "          (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "          (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "      (1): BasicBlock(\n",
       "        (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (layer3): Sequential(\n",
       "      (0): BasicBlock(\n",
       "        (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (downsample): Sequential(\n",
       "          (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "          (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "      (1): BasicBlock(\n",
       "        (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (layer4): Sequential(\n",
       "      (0): BasicBlock(\n",
       "        (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (downsample): Sequential(\n",
       "          (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "          (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "      (1): BasicBlock(\n",
       "        (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
       "    (fc): Linear(in_features=512, out_features=512, bias=True)\n",
       "  )\n",
       "  (paramLayer1): Sequential(\n",
       "    (0): Linear(in_features=9, out_features=10, bias=True)\n",
       "    (1): Tanh()\n",
       "  )\n",
       "  (paramLayer2): Sequential(\n",
       "    (0): Linear(in_features=10, out_features=10, bias=True)\n",
       "    (1): Tanh()\n",
       "  )\n",
       "  (paramLayer3): Sequential(\n",
       "    (0): Linear(in_features=10, out_features=10, bias=True)\n",
       "    (1): Tanh()\n",
       "  )\n",
       "  (paramLayer4): Sequential(\n",
       "    (0): Linear(in_features=10, out_features=10, bias=True)\n",
       "    (1): Tanh()\n",
       "  )\n",
       "  (prediction1): Sequential(\n",
       "    (0): Linear(in_features=522, out_features=100, bias=True)\n",
       "    (1): Tanh()\n",
       "  )\n",
       "  (prediction2): Linear(in_features=100, out_features=24, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "MODEL_PATH = 'trained_models/' + MODEL_NAME + '.pth'\n",
    "\n",
    "torch.cuda.empty_cache()\n",
    "\n",
    "# Load neural network\n",
    "ImgModel = resnet18()\n",
    "ImgModel.conv1 = nn.Conv2d(1, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
    "ImgModel.fc = nn.Linear(512, 512)\n",
    "ImgModel.to(device)\n",
    "model = MeltPoolNetwork(ImgModel, num_classes=NUM_MELT_POOL_CLASSES, num_param=NUM_PROCESS_PARAM).to(device)\n",
    "model.load_state_dict(torch.load(MODEL_PATH))\n",
    "model.to(device)\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Set up LRP and do one sample "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LRP(\n",
       "  (model): MeltPoolNetwork(\n",
       "    (ImageModel): ResNet(\n",
       "      (conv1): Conv2d(1, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
       "      (layer1): Sequential(\n",
       "        (0): BasicBlock(\n",
       "          (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "        (1): BasicBlock(\n",
       "          (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "      (layer2): Sequential(\n",
       "        (0): BasicBlock(\n",
       "          (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "          (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (downsample): Sequential(\n",
       "            (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "            (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          )\n",
       "        )\n",
       "        (1): BasicBlock(\n",
       "          (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "      (layer3): Sequential(\n",
       "        (0): BasicBlock(\n",
       "          (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (downsample): Sequential(\n",
       "            (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "            (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          )\n",
       "        )\n",
       "        (1): BasicBlock(\n",
       "          (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "      (layer4): Sequential(\n",
       "        (0): BasicBlock(\n",
       "          (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "          (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (downsample): Sequential(\n",
       "            (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "            (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          )\n",
       "        )\n",
       "        (1): BasicBlock(\n",
       "          (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "      (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
       "      (fc): Linear(in_features=512, out_features=512, bias=True)\n",
       "    )\n",
       "    (paramLayer1): Sequential(\n",
       "      (0): Linear(in_features=9, out_features=10, bias=True)\n",
       "      (1): Tanh()\n",
       "    )\n",
       "    (paramLayer2): Sequential(\n",
       "      (0): Linear(in_features=10, out_features=10, bias=True)\n",
       "      (1): Tanh()\n",
       "    )\n",
       "    (paramLayer3): Sequential(\n",
       "      (0): Linear(in_features=10, out_features=10, bias=True)\n",
       "      (1): Tanh()\n",
       "    )\n",
       "    (paramLayer4): Sequential(\n",
       "      (0): Linear(in_features=10, out_features=10, bias=True)\n",
       "      (1): Tanh()\n",
       "    )\n",
       "    (prediction1): Sequential(\n",
       "      (0): Linear(in_features=522, out_features=100, bias=True)\n",
       "      (1): Tanh()\n",
       "    )\n",
       "    (prediction2): Linear(in_features=100, out_features=24, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lrp_eps = LRP(model, eps=EPS)\n",
    "lrp_eps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'image': [tensor([-0.0000e+00,  0.0000e+00,  3.0387e-05, -8.2731e-05, -0.0000e+00,\n",
       "          -2.3504e-04,  6.2584e-04, -0.0000e+00, -0.0000e+00,  0.0000e+00,\n",
       "          -2.3426e-04, -0.0000e+00,  0.0000e+00,  0.0000e+00, -7.7892e-03,\n",
       "          -0.0000e+00,  0.0000e+00,  8.0966e-04, -0.0000e+00,  3.0349e-06,\n",
       "          -1.6010e-04, -6.1479e-03,  0.0000e+00,  3.7785e-04, -0.0000e+00,\n",
       "           2.8153e-05, -1.5292e-03, -6.1315e-05,  9.7899e-04, -7.3757e-03,\n",
       "          -3.6224e-03, -1.0508e-03,  3.2394e-03, -0.0000e+00, -0.0000e+00,\n",
       "           0.0000e+00,  0.0000e+00, -5.8511e-04, -0.0000e+00, -1.0569e-03,\n",
       "           0.0000e+00,  7.6765e-04, -3.8838e-02, -0.0000e+00, -1.1759e-04,\n",
       "          -0.0000e+00, -0.0000e+00, -3.2888e-03,  0.0000e+00, -2.3376e-02,\n",
       "           1.1118e-07,  4.5598e-02,  7.6039e-03, -3.1727e-05,  0.0000e+00,\n",
       "          -1.4530e-04,  0.0000e+00, -5.5907e-04,  0.0000e+00,  1.0620e-02,\n",
       "           2.1376e-03,  1.4346e-03,  0.0000e+00,  0.0000e+00, -1.4215e-02,\n",
       "          -5.0524e-05,  1.1976e-04, -2.7086e-05,  0.0000e+00, -0.0000e+00,\n",
       "          -0.0000e+00,  0.0000e+00,  0.0000e+00,  2.3515e-04,  2.0498e-04,\n",
       "          -0.0000e+00, -0.0000e+00,  2.5892e-03, -0.0000e+00,  0.0000e+00,\n",
       "           0.0000e+00,  8.2640e-04, -6.4256e-04, -1.0067e-03,  0.0000e+00,\n",
       "          -3.7015e-04,  0.0000e+00, -0.0000e+00,  6.0548e-03,  8.3092e-03,\n",
       "          -1.1894e-04,  1.7535e-05, -1.5138e-03, -1.2350e-03, -9.4672e-05,\n",
       "          -1.1522e-02,  0.0000e+00,  2.5355e-05, -0.0000e+00, -0.0000e+00,\n",
       "           2.8469e-04,  0.0000e+00,  0.0000e+00, -5.1252e-03,  3.2245e-04,\n",
       "           0.0000e+00, -3.6444e-03, -0.0000e+00, -1.3634e-02,  1.2277e-03,\n",
       "          -0.0000e+00,  4.0306e-04,  0.0000e+00,  6.7964e-05,  6.1215e-04,\n",
       "           0.0000e+00, -0.0000e+00,  2.1331e-01, -5.1032e-04,  1.8824e-04,\n",
       "          -3.3884e-02,  0.0000e+00, -1.2689e-04, -1.6078e-03,  3.6747e-02,\n",
       "          -0.0000e+00, -1.1633e-02, -0.0000e+00,  6.4953e-06,  0.0000e+00,\n",
       "          -1.3259e-03, -2.1874e-02, -0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
       "           2.6865e-04, -0.0000e+00,  0.0000e+00, -3.7945e-04, -0.0000e+00,\n",
       "           0.0000e+00, -2.6961e-04, -6.4500e-05, -1.7599e-02, -3.6490e-04,\n",
       "           0.0000e+00, -3.0887e-04, -0.0000e+00, -0.0000e+00, -2.4467e-04,\n",
       "          -0.0000e+00, -1.0932e-03, -7.6532e-04, -0.0000e+00, -1.3218e-03,\n",
       "           0.0000e+00, -6.8665e-02,  6.9103e-03, -2.3625e-04, -6.1616e-04,\n",
       "          -1.3594e-03,  2.5939e-03,  6.2890e-03,  1.4788e-03,  8.1507e-03,\n",
       "           6.4822e-03,  1.6668e-03,  6.3575e-05,  6.7578e-05, -0.0000e+00,\n",
       "          -5.4116e-04, -5.0571e-04, -1.7959e-02, -2.9895e-04, -6.9830e-05,\n",
       "          -1.0918e-02, -2.1639e-04, -0.0000e+00, -1.5185e-03, -3.0521e-02,\n",
       "          -2.5015e-03, -4.3540e-03,  0.0000e+00, -0.0000e+00, -1.4796e-05,\n",
       "          -0.0000e+00,  1.2203e-04, -0.0000e+00,  1.4352e-04,  2.9584e-03,\n",
       "          -0.0000e+00, -5.4343e-05, -1.7275e-03,  0.0000e+00, -5.8286e-05,\n",
       "          -6.4038e-04, -6.0140e-05,  2.2438e-04, -1.8210e-03, -2.5344e-03,\n",
       "           0.0000e+00, -0.0000e+00,  2.7808e-05,  0.0000e+00, -4.3789e-04,\n",
       "          -1.0319e-05, -4.4768e-04, -1.7606e-04,  3.8320e-03,  0.0000e+00,\n",
       "          -1.3637e-02, -0.0000e+00, -3.0877e-03,  3.4509e-05, -0.0000e+00,\n",
       "          -2.4631e-02,  2.4892e-02,  3.9561e-04, -2.1319e-05, -0.0000e+00,\n",
       "           7.5778e-04, -3.7342e-05, -3.1520e-04, -4.5408e-04, -0.0000e+00,\n",
       "          -1.8944e-03, -2.8529e-04, -6.1559e-04,  6.7537e-05,  1.0977e-03,\n",
       "           0.0000e+00, -0.0000e+00,  2.0028e-03,  5.1969e-04,  5.4903e-03,\n",
       "           0.0000e+00, -4.2656e-03,  0.0000e+00,  1.5819e-03, -9.2659e-06,\n",
       "          -0.0000e+00, -0.0000e+00,  0.0000e+00,  2.2618e-04,  4.5917e-03,\n",
       "           8.6721e-05, -6.4161e-05, -7.3445e-05,  0.0000e+00,  2.1894e-02,\n",
       "          -8.9523e-04, -2.2105e-03,  0.0000e+00,  1.4282e-02, -5.8760e-04,\n",
       "           3.6979e-04, -0.0000e+00,  1.8851e-03,  0.0000e+00,  0.0000e+00,\n",
       "          -9.6440e-03,  0.0000e+00, -3.0515e-06,  0.0000e+00,  8.3513e-05,\n",
       "          -1.6868e-05,  5.0700e-03, -0.0000e+00, -0.0000e+00, -1.0490e-05,\n",
       "           0.0000e+00,  2.4226e-02,  0.0000e+00, -3.9652e-03, -1.1771e-02,\n",
       "           1.4208e-05,  0.0000e+00,  7.9733e-03,  5.1203e-05,  2.7344e-04,\n",
       "          -3.1338e-03, -3.4799e-04, -4.6115e-03, -2.3055e-04,  0.0000e+00,\n",
       "           0.0000e+00,  0.0000e+00,  4.6756e-04,  5.8636e-03,  4.9770e-04,\n",
       "           1.6360e-04,  0.0000e+00,  7.6164e-03,  4.0396e-02, -1.3197e-03,\n",
       "           1.3471e-02,  0.0000e+00,  6.8602e-03, -5.0625e-03, -0.0000e+00,\n",
       "          -0.0000e+00, -1.2790e-04,  4.0799e-03,  2.2760e-03,  0.0000e+00,\n",
       "           1.5308e-04, -3.8912e-04, -2.0687e-05,  0.0000e+00, -0.0000e+00,\n",
       "          -4.1029e-02, -0.0000e+00,  0.0000e+00, -1.0150e-03, -0.0000e+00,\n",
       "           0.0000e+00, -0.0000e+00, -0.0000e+00,  1.0146e-03, -0.0000e+00,\n",
       "          -0.0000e+00,  0.0000e+00,  1.0518e-03,  2.1622e-02, -0.0000e+00,\n",
       "          -7.3631e-04, -2.0759e-02,  3.7005e-03,  0.0000e+00,  0.0000e+00,\n",
       "           3.9158e-03, -0.0000e+00,  2.9347e-04, -8.0768e-03, -0.0000e+00,\n",
       "          -2.7349e-03,  0.0000e+00,  1.6555e-03, -1.2446e-02, -0.0000e+00,\n",
       "          -0.0000e+00,  0.0000e+00,  0.0000e+00, -3.0007e-03,  2.5985e-02,\n",
       "          -5.1045e-04,  3.3936e-03,  0.0000e+00, -0.0000e+00,  8.5843e-03,\n",
       "           4.0016e-02, -1.8707e-03, -0.0000e+00, -1.6393e-04, -0.0000e+00,\n",
       "          -1.4629e-03,  0.0000e+00, -0.0000e+00, -4.4494e-05, -2.2257e-03,\n",
       "          -2.1187e-04, -1.1870e-02, -0.0000e+00, -6.5661e-03,  7.7860e-03,\n",
       "          -2.3964e-04,  1.0192e-02, -3.8601e-05, -2.7808e-03, -9.5393e-04,\n",
       "          -5.8343e-07, -0.0000e+00, -1.4140e-03,  0.0000e+00,  0.0000e+00,\n",
       "           1.4547e-03, -9.0733e-04,  5.1278e-04, -2.9512e-04, -6.7260e-06,\n",
       "          -6.1325e-06,  0.0000e+00,  2.6932e-04,  4.2214e-03,  0.0000e+00,\n",
       "           0.0000e+00, -0.0000e+00,  0.0000e+00,  8.6084e-03, -1.7595e-02,\n",
       "           2.1786e-04, -1.8951e-02, -0.0000e+00,  0.0000e+00,  4.2191e-02,\n",
       "           7.3886e-04, -1.3172e-02,  0.0000e+00, -0.0000e+00,  5.4083e-04,\n",
       "          -3.6926e-03, -6.1336e-03,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
       "          -4.6010e-05,  2.0117e-03, -0.0000e+00, -9.6480e-05, -5.3725e-03,\n",
       "           0.0000e+00, -5.5058e-05,  2.9448e-04,  4.0337e-05, -1.2281e-03,\n",
       "           8.3084e-04,  0.0000e+00,  1.3695e-04, -4.6158e-03, -4.8569e-03,\n",
       "           0.0000e+00, -0.0000e+00, -1.0169e-02,  0.0000e+00, -5.5941e-04,\n",
       "          -6.7318e-05, -0.0000e+00,  4.3797e-03, -7.7204e-04,  2.0255e-03,\n",
       "          -3.5464e-04,  5.2008e-04, -3.1030e-04,  2.0701e-04, -1.5775e-03,\n",
       "           5.4371e-04,  1.2452e-06,  7.8337e-04,  3.7248e-03,  2.6699e-05,\n",
       "          -0.0000e+00,  0.0000e+00,  0.0000e+00, -0.0000e+00,  1.9830e-03,\n",
       "           1.9456e-04,  4.5310e-05, -1.0691e-03,  2.6636e-02,  4.8157e-05,\n",
       "           5.4946e-03,  7.8563e-05,  0.0000e+00,  8.4524e-07, -0.0000e+00,\n",
       "          -0.0000e+00,  0.0000e+00, -2.5096e-03, -2.7978e-05,  0.0000e+00,\n",
       "          -7.6657e-04,  3.6366e-03,  0.0000e+00,  0.0000e+00, -3.2939e-04,\n",
       "           0.0000e+00, -0.0000e+00,  0.0000e+00, -0.0000e+00,  2.6233e-05,\n",
       "           3.9527e-03,  2.6143e-04, -1.7045e-04, -9.9065e-03, -6.2390e-04,\n",
       "           0.0000e+00, -3.4587e-02, -1.7200e-02, -2.6477e-05,  2.2050e-04,\n",
       "           3.8455e-03,  9.8007e-03, -1.2094e-03, -2.1935e-03,  1.0907e-03,\n",
       "          -7.2277e-03, -4.4565e-04, -1.2332e-04,  0.0000e+00,  3.3660e-04,\n",
       "           6.7102e-04,  2.3662e-03, -2.6278e-02, -0.0000e+00,  1.0109e-02,\n",
       "           0.0000e+00,  0.0000e+00,  1.3099e-04,  1.5048e-04,  9.4205e-03,\n",
       "           0.0000e+00, -5.0663e-03,  0.0000e+00, -0.0000e+00,  0.0000e+00,\n",
       "           0.0000e+00,  5.5097e-06, -4.5981e-04, -7.4569e-05, -8.5359e-04,\n",
       "           0.0000e+00, -0.0000e+00], device='cuda:0', grad_fn=<MulBackward0>),\n",
       "  tensor([[[[0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
       "            [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
       "            [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
       "            ...,\n",
       "            [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
       "            [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
       "            [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000]],\n",
       "  \n",
       "           [[0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
       "            [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
       "            [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
       "            ...,\n",
       "            [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
       "            [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
       "            [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000]],\n",
       "  \n",
       "           [[0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
       "            [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
       "            [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
       "            ...,\n",
       "            [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
       "            [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
       "            [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000]],\n",
       "  \n",
       "           ...,\n",
       "  \n",
       "           [[0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
       "            [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
       "            [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
       "            ...,\n",
       "            [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
       "            [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0022],\n",
       "            [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000]],\n",
       "  \n",
       "           [[0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
       "            [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
       "            [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
       "            ...,\n",
       "            [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
       "            [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
       "            [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000]],\n",
       "  \n",
       "           [[0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
       "            [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
       "            [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
       "            ...,\n",
       "            [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
       "            [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
       "            [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000]]]],\n",
       "         device='cuda:0', grad_fn=<MulBackward0>),\n",
       "  tensor([[[[-0.0000e+00, -0.0000e+00, -0.0000e+00,  ..., -0.0000e+00,\n",
       "             -0.0000e+00, -7.2565e-05],\n",
       "            [-0.0000e+00, -0.0000e+00, -0.0000e+00,  ..., -0.0000e+00,\n",
       "             -5.9896e-04, -2.0279e-03],\n",
       "            [-0.0000e+00, -0.0000e+00, -0.0000e+00,  ..., -0.0000e+00,\n",
       "             -0.0000e+00, -2.2061e-03],\n",
       "            ...,\n",
       "            [-0.0000e+00, -0.0000e+00, -0.0000e+00,  ..., -0.0000e+00,\n",
       "             -0.0000e+00, -2.3718e-03],\n",
       "            [-0.0000e+00, -0.0000e+00, -0.0000e+00,  ..., -0.0000e+00,\n",
       "             -0.0000e+00, -3.1215e-03],\n",
       "            [-0.0000e+00, -0.0000e+00, -0.0000e+00,  ..., -0.0000e+00,\n",
       "             -0.0000e+00, -1.3099e-03]],\n",
       "  \n",
       "           [[ 0.0000e+00,  0.0000e+00, -0.0000e+00,  ..., -0.0000e+00,\n",
       "             -0.0000e+00, -0.0000e+00],\n",
       "            [ 0.0000e+00,  0.0000e+00,  2.3111e-03,  ..., -1.2853e-03,\n",
       "             -3.2894e-04, -0.0000e+00],\n",
       "            [ 0.0000e+00,  4.1565e-03,  9.7731e-03,  ...,  0.0000e+00,\n",
       "              0.0000e+00,  0.0000e+00],\n",
       "            ...,\n",
       "            [ 0.0000e+00, -0.0000e+00, -0.0000e+00,  ..., -0.0000e+00,\n",
       "             -0.0000e+00, -1.6837e-03],\n",
       "            [ 0.0000e+00, -0.0000e+00, -0.0000e+00,  ..., -0.0000e+00,\n",
       "             -0.0000e+00,  0.0000e+00],\n",
       "            [ 0.0000e+00, -0.0000e+00, -0.0000e+00,  ..., -0.0000e+00,\n",
       "             -0.0000e+00, -0.0000e+00]],\n",
       "  \n",
       "           [[ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
       "              0.0000e+00,  0.0000e+00],\n",
       "            [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ..., -0.0000e+00,\n",
       "              0.0000e+00,  0.0000e+00],\n",
       "            [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
       "              0.0000e+00,  0.0000e+00],\n",
       "            ...,\n",
       "            [ 0.0000e+00, -0.0000e+00, -0.0000e+00,  ..., -0.0000e+00,\n",
       "             -0.0000e+00,  0.0000e+00],\n",
       "            [ 0.0000e+00, -0.0000e+00, -0.0000e+00,  ...,  0.0000e+00,\n",
       "              0.0000e+00,  0.0000e+00],\n",
       "            [ 0.0000e+00, -0.0000e+00, -0.0000e+00,  ..., -5.1004e-05,\n",
       "              0.0000e+00,  0.0000e+00]],\n",
       "  \n",
       "           ...,\n",
       "  \n",
       "           [[-0.0000e+00, -0.0000e+00, -0.0000e+00,  ..., -0.0000e+00,\n",
       "             -0.0000e+00, -0.0000e+00],\n",
       "            [ 0.0000e+00,  0.0000e+00, -0.0000e+00,  ..., -0.0000e+00,\n",
       "             -0.0000e+00, -1.6599e-05],\n",
       "            [-0.0000e+00, -0.0000e+00, -0.0000e+00,  ..., -0.0000e+00,\n",
       "             -0.0000e+00, -0.0000e+00],\n",
       "            ...,\n",
       "            [-0.0000e+00, -0.0000e+00, -0.0000e+00,  ..., -0.0000e+00,\n",
       "             -0.0000e+00, -1.0522e-03],\n",
       "            [-0.0000e+00, -0.0000e+00, -0.0000e+00,  ..., -0.0000e+00,\n",
       "             -0.0000e+00,  3.4308e-04],\n",
       "            [-0.0000e+00, -0.0000e+00, -0.0000e+00,  ..., -0.0000e+00,\n",
       "             -0.0000e+00, -1.4417e-03]],\n",
       "  \n",
       "           [[ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
       "              0.0000e+00, -0.0000e+00],\n",
       "            [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
       "              0.0000e+00, -0.0000e+00],\n",
       "            [ 0.0000e+00,  2.6084e-03,  6.8521e-03,  ...,  0.0000e+00,\n",
       "              0.0000e+00, -0.0000e+00],\n",
       "            ...,\n",
       "            [-0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
       "              0.0000e+00,  0.0000e+00],\n",
       "            [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
       "              0.0000e+00,  0.0000e+00],\n",
       "            [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
       "              0.0000e+00,  0.0000e+00]],\n",
       "  \n",
       "           [[-0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
       "              0.0000e+00,  0.0000e+00],\n",
       "            [-0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
       "              0.0000e+00,  0.0000e+00],\n",
       "            [ 0.0000e+00, -0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
       "              0.0000e+00,  0.0000e+00],\n",
       "            ...,\n",
       "            [ 0.0000e+00, -0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
       "             -0.0000e+00,  0.0000e+00],\n",
       "            [-0.0000e+00, -0.0000e+00,  0.0000e+00,  ..., -0.0000e+00,\n",
       "             -0.0000e+00,  0.0000e+00],\n",
       "            [-0.0000e+00, -0.0000e+00,  0.0000e+00,  ..., -0.0000e+00,\n",
       "             -0.0000e+00,  0.0000e+00]]]], device='cuda:0',\n",
       "         grad_fn=<MulBackward0>),\n",
       "  tensor([[[[ 0.0000e+00,  0.0000e+00,  2.3490e-04,  ..., -6.1028e-05,\n",
       "             -8.4633e-05, -0.0000e+00],\n",
       "            [ 0.0000e+00,  0.0000e+00, -1.6140e-05,  ..., -2.8078e-04,\n",
       "             -1.9134e-06, -0.0000e+00],\n",
       "            [ 0.0000e+00,  1.9304e-04,  3.1201e-05,  ...,  1.2610e-04,\n",
       "             -0.0000e+00, -0.0000e+00],\n",
       "            ...,\n",
       "            [ 2.1121e-04, -0.0000e+00,  0.0000e+00,  ..., -0.0000e+00,\n",
       "              0.0000e+00,  0.0000e+00],\n",
       "            [ 2.4151e-04, -0.0000e+00,  0.0000e+00,  ..., -0.0000e+00,\n",
       "             -0.0000e+00, -0.0000e+00],\n",
       "            [ 0.0000e+00, -0.0000e+00, -0.0000e+00,  ..., -0.0000e+00,\n",
       "              0.0000e+00, -0.0000e+00]],\n",
       "  \n",
       "           [[ 5.8931e-04,  2.2564e-06,  0.0000e+00,  ...,  5.1491e-05,\n",
       "              0.0000e+00,  0.0000e+00],\n",
       "            [ 3.1752e-04,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
       "              0.0000e+00,  0.0000e+00],\n",
       "            [-4.6121e-05, -0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
       "             -0.0000e+00,  0.0000e+00],\n",
       "            ...,\n",
       "            [ 0.0000e+00, -2.0935e-05, -2.5559e-04,  ...,  0.0000e+00,\n",
       "              0.0000e+00,  2.0790e-04],\n",
       "            [ 6.4766e-06, -1.9033e-05, -4.0827e-04,  ...,  5.5742e-06,\n",
       "             -0.0000e+00,  4.5686e-05],\n",
       "            [ 4.6097e-05,  1.6113e-04, -1.3275e-05,  ..., -0.0000e+00,\n",
       "             -3.6720e-07,  4.6937e-06]],\n",
       "  \n",
       "           [[-0.0000e+00,  0.0000e+00, -0.0000e+00,  ..., -0.0000e+00,\n",
       "              6.7333e-08, -3.5010e-06],\n",
       "            [-0.0000e+00, -0.0000e+00, -0.0000e+00,  ..., -0.0000e+00,\n",
       "             -1.9525e-05, -8.7474e-05],\n",
       "            [ 0.0000e+00, -0.0000e+00,  0.0000e+00,  ..., -0.0000e+00,\n",
       "             -6.5219e-05, -3.6815e-05],\n",
       "            ...,\n",
       "            [-0.0000e+00, -0.0000e+00, -0.0000e+00,  ..., -4.7739e-05,\n",
       "             -0.0000e+00, -0.0000e+00],\n",
       "            [-0.0000e+00, -0.0000e+00, -0.0000e+00,  ..., -2.7719e-06,\n",
       "             -0.0000e+00, -0.0000e+00],\n",
       "            [-0.0000e+00, -0.0000e+00, -0.0000e+00,  ..., -1.2714e-04,\n",
       "             -0.0000e+00, -0.0000e+00]],\n",
       "  \n",
       "           ...,\n",
       "  \n",
       "           [[-0.0000e+00, -0.0000e+00, -0.0000e+00,  ..., -0.0000e+00,\n",
       "              0.0000e+00,  0.0000e+00],\n",
       "            [-0.0000e+00,  0.0000e+00,  0.0000e+00,  ..., -0.0000e+00,\n",
       "              0.0000e+00,  0.0000e+00],\n",
       "            [-0.0000e+00, -0.0000e+00, -0.0000e+00,  ..., -0.0000e+00,\n",
       "              0.0000e+00,  0.0000e+00],\n",
       "            ...,\n",
       "            [-0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
       "              0.0000e+00,  0.0000e+00],\n",
       "            [-0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
       "             -0.0000e+00, -0.0000e+00],\n",
       "            [-0.0000e+00,  4.6869e-07,  0.0000e+00,  ...,  0.0000e+00,\n",
       "             -0.0000e+00, -0.0000e+00]],\n",
       "  \n",
       "           [[-0.0000e+00,  0.0000e+00,  0.0000e+00,  ..., -7.0764e-07,\n",
       "              1.1713e-06,  4.2662e-07],\n",
       "            [-0.0000e+00, -0.0000e+00, -0.0000e+00,  ..., -1.6480e-05,\n",
       "             -4.4952e-06, -1.8060e-06],\n",
       "            [-2.7686e-07, -1.1256e-05,  0.0000e+00,  ..., -1.2825e-05,\n",
       "             -1.9454e-05,  8.9150e-07],\n",
       "            ...,\n",
       "            [-0.0000e+00,  0.0000e+00,  3.0278e-05,  ..., -1.9054e-06,\n",
       "             -4.5329e-06, -2.1471e-05],\n",
       "            [-0.0000e+00, -0.0000e+00,  3.5571e-07,  ..., -2.0723e-06,\n",
       "             -0.0000e+00, -0.0000e+00],\n",
       "            [-0.0000e+00, -0.0000e+00, -0.0000e+00,  ..., -1.0908e-06,\n",
       "             -7.5367e-06, -0.0000e+00]],\n",
       "  \n",
       "           [[ 3.9719e-05,  1.2951e-05, -1.1521e-04,  ..., -0.0000e+00,\n",
       "             -0.0000e+00, -0.0000e+00],\n",
       "            [-1.0313e-05, -2.5338e-05, -1.0776e-05,  ..., -0.0000e+00,\n",
       "              0.0000e+00,  0.0000e+00],\n",
       "            [ 2.3829e-04,  1.9564e-06,  0.0000e+00,  ..., -0.0000e+00,\n",
       "              0.0000e+00,  0.0000e+00],\n",
       "            ...,\n",
       "            [ 0.0000e+00, -0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
       "              0.0000e+00,  0.0000e+00],\n",
       "            [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
       "             -0.0000e+00,  0.0000e+00],\n",
       "            [ 6.1449e-06, -1.6350e-06, -2.9983e-06,  ..., -0.0000e+00,\n",
       "              0.0000e+00, -3.4461e-07]]]], device='cuda:0',\n",
       "         grad_fn=<MulBackward0>),\n",
       "  tensor([[[[-0.0000e+00, -0.0000e+00,  2.2464e-04,  ..., -8.6553e-05,\n",
       "             -1.2330e-04, -3.1242e-07],\n",
       "            [-0.0000e+00, -0.0000e+00, -1.2230e-05,  ..., -3.9714e-04,\n",
       "             -5.5691e-05, -2.8128e-05],\n",
       "            [-0.0000e+00,  1.5347e-04,  6.4744e-05,  ...,  3.5709e-05,\n",
       "             -4.2772e-05, -9.3510e-06],\n",
       "            ...,\n",
       "            [ 2.1785e-04,  0.0000e+00,  0.0000e+00,  ..., -0.0000e+00,\n",
       "             -0.0000e+00, -0.0000e+00],\n",
       "            [ 1.9087e-04, -0.0000e+00, -0.0000e+00,  ..., -0.0000e+00,\n",
       "             -0.0000e+00, -0.0000e+00],\n",
       "            [-3.5146e-06, -4.3739e-07, -0.0000e+00,  ..., -0.0000e+00,\n",
       "             -0.0000e+00, -0.0000e+00]],\n",
       "  \n",
       "           [[ 5.5491e-04,  1.8589e-05,  2.2090e-07,  ...,  1.5574e-04,\n",
       "             -3.9552e-06,  2.4923e-06],\n",
       "            [ 3.0752e-04,  5.3972e-06,  3.4035e-07,  ...,  1.3200e-05,\n",
       "             -4.9237e-06,  8.1173e-06],\n",
       "            [-4.3380e-05,  0.0000e+00,  1.3636e-05,  ...,  5.7610e-05,\n",
       "              2.9284e-05,  2.4830e-06],\n",
       "            ...,\n",
       "            [-3.2021e-06, -6.9387e-05, -3.0972e-04,  ...,  9.6909e-06,\n",
       "             -1.6067e-05,  2.0152e-04],\n",
       "            [-2.6475e-05, -4.7033e-05, -3.7005e-04,  ..., -9.8870e-06,\n",
       "             -3.7565e-05, -3.5217e-05],\n",
       "            [-7.9408e-05,  2.1265e-06, -1.0762e-04,  ..., -3.7512e-05,\n",
       "             -6.4553e-05, -8.2507e-05]],\n",
       "  \n",
       "           [[-0.0000e+00, -0.0000e+00,  2.1731e-06,  ..., -0.0000e+00,\n",
       "             -1.3063e-05, -3.0176e-06],\n",
       "            [-0.0000e+00, -0.0000e+00,  0.0000e+00,  ..., -0.0000e+00,\n",
       "             -7.2499e-05, -1.3717e-04],\n",
       "            [-0.0000e+00, -0.0000e+00,  0.0000e+00,  ..., -0.0000e+00,\n",
       "             -1.7362e-04, -1.3858e-04],\n",
       "            ...,\n",
       "            [ 0.0000e+00,  0.0000e+00, -0.0000e+00,  ..., -8.0955e-05,\n",
       "             -0.0000e+00, -0.0000e+00],\n",
       "            [-0.0000e+00, -0.0000e+00, -0.0000e+00,  ..., -1.4097e-05,\n",
       "             -0.0000e+00, -0.0000e+00],\n",
       "            [-9.0222e-06, -0.0000e+00, -1.7321e-05,  ..., -1.4790e-04,\n",
       "             -0.0000e+00, -0.0000e+00]],\n",
       "  \n",
       "           ...,\n",
       "  \n",
       "           [[ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
       "              0.0000e+00,  0.0000e+00],\n",
       "            [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
       "              0.0000e+00,  0.0000e+00],\n",
       "            [-0.0000e+00, -0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
       "              0.0000e+00,  0.0000e+00],\n",
       "            ...,\n",
       "            [ 0.0000e+00, -0.0000e+00, -0.0000e+00,  ...,  0.0000e+00,\n",
       "              0.0000e+00,  0.0000e+00],\n",
       "            [ 1.2223e-05,  0.0000e+00, -0.0000e+00,  ...,  0.0000e+00,\n",
       "              0.0000e+00,  3.0793e-05],\n",
       "            [-1.5585e-07,  2.2393e-05,  1.0322e-05,  ...,  0.0000e+00,\n",
       "             -0.0000e+00,  0.0000e+00]],\n",
       "  \n",
       "           [[-0.0000e+00, -0.0000e+00, -0.0000e+00,  ...,  0.0000e+00,\n",
       "              0.0000e+00,  0.0000e+00],\n",
       "            [-0.0000e+00, -0.0000e+00, -0.0000e+00,  ..., -0.0000e+00,\n",
       "              0.0000e+00,  0.0000e+00],\n",
       "            [-0.0000e+00, -0.0000e+00, -0.0000e+00,  ..., -0.0000e+00,\n",
       "             -0.0000e+00,  0.0000e+00],\n",
       "            ...,\n",
       "            [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ..., -0.0000e+00,\n",
       "             -9.5549e-07, -1.0010e-05],\n",
       "            [-0.0000e+00, -0.0000e+00, -0.0000e+00,  ..., -0.0000e+00,\n",
       "             -0.0000e+00, -0.0000e+00],\n",
       "            [-0.0000e+00, -0.0000e+00, -0.0000e+00,  ..., -6.5739e-07,\n",
       "             -6.0665e-06, -0.0000e+00]],\n",
       "  \n",
       "           [[ 0.0000e+00,  0.0000e+00, -2.4283e-05,  ...,  0.0000e+00,\n",
       "              0.0000e+00,  0.0000e+00],\n",
       "            [-0.0000e+00, -0.0000e+00, -0.0000e+00,  ...,  0.0000e+00,\n",
       "              0.0000e+00,  0.0000e+00],\n",
       "            [ 0.0000e+00, -0.0000e+00, -0.0000e+00,  ..., -0.0000e+00,\n",
       "              0.0000e+00,  0.0000e+00],\n",
       "            ...,\n",
       "            [-0.0000e+00, -1.4229e-06, -0.0000e+00,  ..., -0.0000e+00,\n",
       "              0.0000e+00,  0.0000e+00],\n",
       "            [-0.0000e+00, -0.0000e+00, -0.0000e+00,  ...,  0.0000e+00,\n",
       "             -0.0000e+00, -0.0000e+00],\n",
       "            [ 0.0000e+00, -0.0000e+00, -0.0000e+00,  ...,  0.0000e+00,\n",
       "              0.0000e+00, -0.0000e+00]]]], device='cuda:0',\n",
       "         grad_fn=<MulBackward0>),\n",
       "  tensor([[[[ 7.3041e-05,  0.0000e+00,  1.7558e-05,  ...,  0.0000e+00,\n",
       "              3.7388e-06,  4.0312e-06],\n",
       "            [ 6.9589e-05,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
       "              0.0000e+00,  0.0000e+00],\n",
       "            [ 2.1529e-05,  6.9449e-05, -0.0000e+00,  ...,  0.0000e+00,\n",
       "              0.0000e+00,  0.0000e+00],\n",
       "            ...,\n",
       "            [-9.8225e-06, -0.0000e+00, -0.0000e+00,  ..., -0.0000e+00,\n",
       "              0.0000e+00,  8.9868e-06],\n",
       "            [-5.3488e-05, -6.5073e-05, -4.3940e-05,  ..., -6.8654e-05,\n",
       "              4.5507e-08,  1.6397e-06],\n",
       "            [-5.2295e-07, -0.0000e+00, -4.6834e-06,  ...,  1.7548e-05,\n",
       "              5.2504e-05,  0.0000e+00]],\n",
       "  \n",
       "           [[ 1.2063e-05, -0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
       "              0.0000e+00,  2.1117e-07],\n",
       "            [-4.4994e-05, -0.0000e+00, -5.5374e-07,  ...,  0.0000e+00,\n",
       "             -0.0000e+00,  0.0000e+00],\n",
       "            [-0.0000e+00, -0.0000e+00, -4.0475e-07,  ...,  0.0000e+00,\n",
       "              0.0000e+00,  0.0000e+00],\n",
       "            ...,\n",
       "            [-0.0000e+00,  0.0000e+00,  7.0450e-05,  ...,  1.0900e-04,\n",
       "              7.0646e-05,  0.0000e+00],\n",
       "            [ 0.0000e+00,  1.1978e-06,  1.6632e-04,  ...,  1.0211e-04,\n",
       "              8.8273e-05,  0.0000e+00],\n",
       "            [-0.0000e+00,  2.6842e-07,  2.2385e-05,  ...,  3.7979e-05,\n",
       "              1.0043e-05,  1.5457e-05]],\n",
       "  \n",
       "           [[ 0.0000e+00,  5.1079e-05,  1.4404e-04,  ..., -0.0000e+00,\n",
       "             -1.5630e-06, -4.4708e-06],\n",
       "            [ 0.0000e+00,  1.2124e-04,  0.0000e+00,  ..., -0.0000e+00,\n",
       "             -0.0000e+00, -0.0000e+00],\n",
       "            [ 0.0000e+00,  1.1422e-04,  0.0000e+00,  ..., -0.0000e+00,\n",
       "             -0.0000e+00, -0.0000e+00],\n",
       "            ...,\n",
       "            [ 7.0150e-06,  2.4009e-06, -0.0000e+00,  ..., -0.0000e+00,\n",
       "             -1.1481e-06,  1.1003e-05],\n",
       "            [-4.6526e-05, -0.0000e+00, -0.0000e+00,  ..., -0.0000e+00,\n",
       "              0.0000e+00, -0.0000e+00],\n",
       "            [-0.0000e+00, -0.0000e+00, -1.5393e-05,  ..., -2.3005e-05,\n",
       "             -0.0000e+00,  0.0000e+00]],\n",
       "  \n",
       "           ...,\n",
       "  \n",
       "           [[ 0.0000e+00, -2.5509e-07,  0.0000e+00,  ...,  0.0000e+00,\n",
       "             -0.0000e+00, -0.0000e+00],\n",
       "            [ 0.0000e+00,  1.2711e-05,  0.0000e+00,  ..., -0.0000e+00,\n",
       "             -0.0000e+00, -0.0000e+00],\n",
       "            [ 0.0000e+00, -1.9763e-07,  0.0000e+00,  ..., -1.0493e-06,\n",
       "             -0.0000e+00, -0.0000e+00],\n",
       "            ...,\n",
       "            [ 2.2568e-06, -0.0000e+00, -3.4428e-06,  ..., -0.0000e+00,\n",
       "             -0.0000e+00, -0.0000e+00],\n",
       "            [ 0.0000e+00,  0.0000e+00, -3.0404e-05,  ..., -0.0000e+00,\n",
       "             -0.0000e+00, -0.0000e+00],\n",
       "            [-4.9044e-07, -0.0000e+00, -0.0000e+00,  ..., -0.0000e+00,\n",
       "             -0.0000e+00, -0.0000e+00]],\n",
       "  \n",
       "           [[-1.1142e-04,  1.4213e-06,  6.2926e-05,  ..., -2.0239e-05,\n",
       "             -3.4615e-05, -6.7963e-06],\n",
       "            [-6.5193e-05, -2.4359e-05, -1.4692e-05,  ..., -8.5699e-05,\n",
       "             -4.8373e-05, -4.4865e-05],\n",
       "            [-2.6140e-05, -1.8192e-05,  7.5262e-05,  ..., -7.7176e-05,\n",
       "             -1.3672e-04, -5.1149e-05],\n",
       "            ...,\n",
       "            [-2.9932e-05, -1.3373e-05,  1.9333e-06,  ..., -2.5881e-05,\n",
       "             -2.5510e-04, -1.4878e-04],\n",
       "            [-6.6401e-05, -5.0705e-05, -6.5273e-06,  ..., -2.4818e-05,\n",
       "             -2.0186e-04, -1.2825e-04],\n",
       "            [ 3.8387e-06,  3.4501e-05,  7.5212e-06,  ..., -3.8365e-05,\n",
       "             -6.4254e-05, -6.9209e-05]],\n",
       "  \n",
       "           [[-4.8504e-05,  0.0000e+00, -0.0000e+00,  ..., -0.0000e+00,\n",
       "             -0.0000e+00, -0.0000e+00],\n",
       "            [ 3.5227e-07,  0.0000e+00,  0.0000e+00,  ..., -0.0000e+00,\n",
       "              2.4881e-06,  0.0000e+00],\n",
       "            [-0.0000e+00,  0.0000e+00, -0.0000e+00,  ..., -0.0000e+00,\n",
       "             -0.0000e+00, -0.0000e+00],\n",
       "            ...,\n",
       "            [ 0.0000e+00, -0.0000e+00,  0.0000e+00,  ..., -1.6197e-05,\n",
       "             -8.2917e-08, -0.0000e+00],\n",
       "            [ 0.0000e+00, -0.0000e+00,  0.0000e+00,  ..., -2.5258e-06,\n",
       "             -0.0000e+00, -4.1237e-08],\n",
       "            [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ..., -0.0000e+00,\n",
       "             -0.0000e+00,  0.0000e+00]]]], device='cuda:0',\n",
       "         grad_fn=<MulBackward0>),\n",
       "  tensor([[[[ 1.0093e-04, -1.3985e-06,  2.9281e-05,  ..., -3.2019e-06,\n",
       "             -1.3375e-05, -1.7939e-05],\n",
       "            [ 9.6814e-05,  1.8504e-06,  1.8789e-07,  ...,  0.0000e+00,\n",
       "             -0.0000e+00, -9.6875e-08],\n",
       "            [ 3.8909e-06,  4.4240e-05, -0.0000e+00,  ...,  0.0000e+00,\n",
       "              0.0000e+00, -0.0000e+00],\n",
       "            ...,\n",
       "            [-4.9570e-05,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
       "             -2.7057e-07,  5.8293e-07],\n",
       "            [-1.4677e-04, -8.8700e-05, -5.9970e-05,  ..., -1.6482e-04,\n",
       "             -1.8259e-05, -1.8514e-05],\n",
       "            [-1.0678e-06, -3.0500e-07, -3.1168e-06,  ..., -5.4207e-06,\n",
       "              4.0407e-05, -0.0000e+00]],\n",
       "  \n",
       "           [[ 3.4630e-05,  0.0000e+00, -0.0000e+00,  ...,  0.0000e+00,\n",
       "              0.0000e+00, -2.2675e-06],\n",
       "            [-1.4678e-05, -0.0000e+00, -0.0000e+00,  ...,  0.0000e+00,\n",
       "              0.0000e+00, -0.0000e+00],\n",
       "            [-0.0000e+00, -0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
       "              0.0000e+00, -0.0000e+00],\n",
       "            ...,\n",
       "            [-0.0000e+00, -0.0000e+00,  1.7135e-04,  ...,  8.0467e-05,\n",
       "              7.5620e-05,  2.7029e-06],\n",
       "            [ 0.0000e+00,  2.9164e-06,  2.4161e-04,  ...,  6.9614e-05,\n",
       "              7.6114e-05,  0.0000e+00],\n",
       "            [-0.0000e+00,  3.1139e-06,  2.6919e-05,  ...,  3.9499e-05,\n",
       "              1.2984e-05,  2.4970e-05]],\n",
       "  \n",
       "           [[-1.2523e-05,  3.9126e-05,  4.9765e-05,  ...,  4.3347e-06,\n",
       "             -3.6739e-06, -1.7651e-05],\n",
       "            [-1.4030e-05,  9.5063e-05,  4.9177e-07,  ...,  0.0000e+00,\n",
       "              2.0234e-06,  1.1982e-06],\n",
       "            [-1.6489e-06,  8.0338e-05, -1.3831e-05,  ...,  3.1465e-06,\n",
       "              0.0000e+00,  8.0891e-07],\n",
       "            ...,\n",
       "            [-1.2204e-05, -6.0378e-05, -0.0000e+00,  ...,  4.5048e-05,\n",
       "             -7.9034e-06, -1.7842e-05],\n",
       "            [-8.2167e-05, -0.0000e+00,  0.0000e+00,  ...,  6.1841e-06,\n",
       "              2.1790e-06, -2.9397e-06],\n",
       "            [-3.8386e-07, -0.0000e+00, -5.0999e-05,  ..., -4.1091e-05,\n",
       "              7.4881e-07,  5.4494e-06]],\n",
       "  \n",
       "           ...,\n",
       "  \n",
       "           [[-7.7851e-07, -4.3590e-06, -0.0000e+00,  ...,  4.3708e-06,\n",
       "              0.0000e+00, -7.5053e-08],\n",
       "            [-0.0000e+00, -1.3188e-06, -0.0000e+00,  ...,  0.0000e+00,\n",
       "              0.0000e+00, -0.0000e+00],\n",
       "            [-0.0000e+00, -0.0000e+00, -0.0000e+00,  ..., -2.7507e-06,\n",
       "              0.0000e+00, -0.0000e+00],\n",
       "            ...,\n",
       "            [ 2.6727e-06, -0.0000e+00,  5.6557e-06,  ..., -1.2586e-05,\n",
       "             -0.0000e+00, -8.4698e-07],\n",
       "            [-0.0000e+00, -0.0000e+00, -1.0105e-04,  ..., -0.0000e+00,\n",
       "             -0.0000e+00,  0.0000e+00],\n",
       "            [-0.0000e+00, -0.0000e+00, -9.4037e-06,  ..., -0.0000e+00,\n",
       "              0.0000e+00, -1.1001e-06]],\n",
       "  \n",
       "           [[-1.0376e-04, -4.2819e-07,  6.6637e-05,  ..., -2.2936e-05,\n",
       "             -2.9936e-05,  4.6187e-07],\n",
       "            [-5.7648e-05, -9.2951e-06,  1.8189e-05,  ..., -1.2591e-04,\n",
       "             -7.6403e-05, -4.5887e-05],\n",
       "            [-1.7181e-05,  1.7505e-05,  7.9823e-05,  ..., -1.1967e-04,\n",
       "             -1.5865e-04, -5.7575e-05],\n",
       "            ...,\n",
       "            [-6.8181e-06,  2.0236e-04,  7.1320e-06,  ..., -2.7903e-06,\n",
       "             -2.2743e-04, -1.2343e-04],\n",
       "            [-5.2067e-05,  2.0574e-05, -1.8897e-06,  ..., -7.2367e-06,\n",
       "             -1.6260e-04, -1.0527e-04],\n",
       "            [ 1.4931e-05,  4.4413e-05,  2.0096e-07,  ..., -2.8878e-05,\n",
       "             -5.7771e-05, -4.9064e-05]],\n",
       "  \n",
       "           [[-0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
       "             -0.0000e+00, -7.4658e-08],\n",
       "            [ 0.0000e+00,  5.1227e-06, -0.0000e+00,  ...,  0.0000e+00,\n",
       "              2.5325e-05,  0.0000e+00],\n",
       "            [ 0.0000e+00,  0.0000e+00, -0.0000e+00,  ...,  0.0000e+00,\n",
       "              0.0000e+00,  0.0000e+00],\n",
       "            ...,\n",
       "            [-0.0000e+00, -0.0000e+00, -0.0000e+00,  ..., -0.0000e+00,\n",
       "             -0.0000e+00,  0.0000e+00],\n",
       "            [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ..., -0.0000e+00,\n",
       "             -0.0000e+00,  0.0000e+00],\n",
       "            [ 2.7987e-06,  0.0000e+00,  0.0000e+00,  ..., -0.0000e+00,\n",
       "             -0.0000e+00,  0.0000e+00]]]], device='cuda:0',\n",
       "         grad_fn=<MulBackward0>),\n",
       "  tensor([[[[ 6.3475e-05,  3.1818e-05,  1.1351e-04,  ...,  5.2257e-06,\n",
       "              3.2004e-06,  1.1643e-07],\n",
       "            [ 1.2135e-05,  5.0658e-05,  2.2629e-05,  ...,  7.0875e-06,\n",
       "              3.7678e-06,  2.7825e-06],\n",
       "            [ 2.5593e-05, -2.8058e-06,  8.6890e-06,  ...,  6.0607e-06,\n",
       "              2.7399e-05,  4.7194e-06],\n",
       "            ...,\n",
       "            [-4.3740e-06, -3.0489e-06, -7.4928e-06,  ...,  4.8522e-05,\n",
       "              1.7300e-05,  1.1935e-05],\n",
       "            [-1.3285e-06, -0.0000e+00, -3.0739e-06,  ...,  1.2878e-05,\n",
       "              1.1260e-04,  4.2308e-06],\n",
       "            [ 1.3321e-06, -2.5804e-06,  1.5549e-06,  ...,  1.9934e-05,\n",
       "              1.0288e-05,  8.8441e-06]],\n",
       "  \n",
       "           [[-4.5467e-05, -1.7303e-05, -2.7770e-05,  ..., -2.1045e-06,\n",
       "              1.7586e-06,  2.1177e-07],\n",
       "            [-1.6949e-05, -2.6119e-05, -1.4619e-05,  ..., -5.9271e-06,\n",
       "             -9.4931e-07,  9.6683e-09],\n",
       "            [-2.7986e-05, -8.5189e-06, -2.8521e-05,  ..., -9.0103e-06,\n",
       "             -2.2702e-05, -1.3836e-06],\n",
       "            ...,\n",
       "            [ 1.2489e-05,  2.3961e-05,  2.3586e-05,  ..., -5.1629e-05,\n",
       "             -2.5400e-05, -1.2822e-05],\n",
       "            [ 6.9378e-06,  3.1254e-06,  2.3753e-05,  ..., -2.1581e-05,\n",
       "             -5.4724e-05, -5.7269e-06],\n",
       "            [-3.9830e-06, -3.0450e-06, -1.4474e-06,  ..., -1.2406e-05,\n",
       "             -6.5078e-06, -6.0245e-06]],\n",
       "  \n",
       "           [[ 0.0000e+00, -0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
       "              0.0000e+00,  0.0000e+00],\n",
       "            [-0.0000e+00, -0.0000e+00, -0.0000e+00,  ...,  0.0000e+00,\n",
       "              0.0000e+00,  0.0000e+00],\n",
       "            [ 0.0000e+00,  0.0000e+00, -0.0000e+00,  ...,  0.0000e+00,\n",
       "              0.0000e+00,  0.0000e+00],\n",
       "            ...,\n",
       "            [-0.0000e+00, -0.0000e+00, -0.0000e+00,  ...,  0.0000e+00,\n",
       "              0.0000e+00,  0.0000e+00],\n",
       "            [ 0.0000e+00, -0.0000e+00,  0.0000e+00,  ..., -0.0000e+00,\n",
       "              0.0000e+00,  0.0000e+00],\n",
       "            [-0.0000e+00, -0.0000e+00, -0.0000e+00,  ..., -0.0000e+00,\n",
       "             -0.0000e+00,  0.0000e+00]],\n",
       "  \n",
       "           ...,\n",
       "  \n",
       "           [[ 4.6275e-05, -3.3275e-05,  8.1261e-05,  ..., -1.7751e-05,\n",
       "             -3.2335e-05, -3.7621e-06],\n",
       "            [-2.9844e-05, -5.0682e-05, -4.5792e-05,  ..., -3.9627e-05,\n",
       "             -1.3546e-05, -1.0255e-05],\n",
       "            [ 3.4192e-05, -5.8240e-06,  1.8534e-04,  ..., -4.6892e-05,\n",
       "             -1.1266e-04, -1.5755e-05],\n",
       "            ...,\n",
       "            [ 2.1088e-05,  1.2619e-04,  1.1731e-04,  ..., -9.0553e-05,\n",
       "             -3.2621e-05, -2.9384e-05],\n",
       "            [ 5.5591e-05,  4.5396e-05,  1.6501e-04,  ..., -2.4288e-05,\n",
       "             -7.5092e-05, -2.8902e-06],\n",
       "            [ 9.5474e-06,  4.5614e-05,  2.7202e-05,  ..., -2.6296e-05,\n",
       "             -4.7339e-06, -1.0183e-05]],\n",
       "  \n",
       "           [[ 2.2100e-05, -0.0000e+00,  0.0000e+00,  ..., -1.0084e-06,\n",
       "             -2.0037e-06, -3.4643e-07],\n",
       "            [-1.4697e-05, -0.0000e+00,  0.0000e+00,  ..., -1.1519e-06,\n",
       "             -3.3037e-06, -3.5665e-07],\n",
       "            [ 2.0262e-05,  0.0000e+00,  0.0000e+00,  ..., -1.6768e-06,\n",
       "             -1.9323e-06, -5.3019e-07],\n",
       "            ...,\n",
       "            [-1.0996e-07,  1.6416e-06,  5.8410e-06,  ..., -0.0000e+00,\n",
       "              1.2178e-07,  1.2812e-06],\n",
       "            [ 2.4573e-06,  1.4256e-06,  2.8122e-05,  ...,  8.4470e-08,\n",
       "              2.6861e-06, -0.0000e+00],\n",
       "            [ 1.7003e-07,  4.9767e-07, -3.3382e-06,  ...,  3.4335e-07,\n",
       "             -9.7159e-07, -9.6763e-08]],\n",
       "  \n",
       "           [[ 2.8770e-05, -1.5722e-05, -1.0798e-05,  ..., -3.2265e-06,\n",
       "             -2.0250e-06, -3.9509e-06],\n",
       "            [-1.2967e-06, -8.9590e-08, -1.3502e-05,  ..., -1.4380e-06,\n",
       "              2.5535e-06, -4.5012e-06],\n",
       "            [ 0.0000e+00, -6.4309e-05,  3.9385e-05,  ..., -6.4569e-06,\n",
       "             -2.0717e-06, -1.8158e-05],\n",
       "            ...,\n",
       "            [ 3.1167e-05,  1.5216e-05,  2.2130e-06,  ..., -3.7862e-05,\n",
       "             -1.5408e-05, -3.0174e-05],\n",
       "            [ 2.0044e-05,  1.0197e-05,  1.3337e-05,  ..., -2.0502e-06,\n",
       "             -9.7463e-06, -2.7639e-05],\n",
       "            [ 3.2863e-05,  1.4148e-05, -1.3042e-06,  ..., -2.4658e-05,\n",
       "             -1.2026e-05, -4.1398e-07]]]], device='cuda:0',\n",
       "         grad_fn=<MulBackward0>),\n",
       "  tensor([[[[ 6.0457e-05,  4.1124e-05,  1.0017e-04,  ...,  7.1387e-06,\n",
       "              3.2340e-06, -2.0362e-06],\n",
       "            [ 1.9692e-05,  6.1448e-05,  3.6616e-05,  ...,  1.1826e-05,\n",
       "              7.9652e-06,  2.1253e-06],\n",
       "            [ 3.0443e-05,  6.5830e-06,  1.7544e-05,  ...,  1.0251e-05,\n",
       "              2.6296e-05,  1.7233e-06],\n",
       "            ...,\n",
       "            [-4.8543e-06, -1.2425e-05, -2.4910e-05,  ...,  4.0587e-05,\n",
       "              2.7754e-05,  1.2066e-05],\n",
       "            [ 9.7909e-07, -3.1284e-06, -1.0189e-05,  ...,  1.8956e-05,\n",
       "              1.0409e-04,  5.4231e-06],\n",
       "            [ 5.5175e-06, -5.5147e-06, -9.2499e-06,  ...,  1.7295e-05,\n",
       "              3.0710e-05,  1.6533e-05]],\n",
       "  \n",
       "           [[-1.2954e-05, -7.3744e-06, -7.6275e-06,  ..., -4.4739e-07,\n",
       "              3.0386e-06,  9.0341e-07],\n",
       "            [-1.2472e-06, -1.5836e-05,  1.7014e-05,  ..., -3.2633e-06,\n",
       "              3.8233e-06,  1.7425e-06],\n",
       "            [-6.3270e-06, -9.6027e-06,  4.5465e-06,  ..., -4.0569e-06,\n",
       "             -3.0175e-06,  5.8190e-07],\n",
       "            ...,\n",
       "            [ 3.2346e-06,  2.0186e-05,  2.3770e-06,  ..., -2.0101e-05,\n",
       "             -1.8071e-06, -2.3378e-06],\n",
       "            [ 7.9103e-06,  8.0697e-06,  3.3583e-06,  ..., -7.8878e-06,\n",
       "             -1.7301e-05,  9.6129e-06],\n",
       "            [ 2.2125e-06,  3.0485e-06, -4.8944e-06,  ..., -1.5759e-05,\n",
       "             -4.1066e-06,  9.9437e-06]],\n",
       "  \n",
       "           [[-0.0000e+00, -0.0000e+00, -0.0000e+00,  ..., -0.0000e+00,\n",
       "             -0.0000e+00, -0.0000e+00],\n",
       "            [-0.0000e+00,  0.0000e+00, -0.0000e+00,  ..., -0.0000e+00,\n",
       "             -0.0000e+00, -0.0000e+00],\n",
       "            [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ..., -0.0000e+00,\n",
       "             -0.0000e+00, -0.0000e+00],\n",
       "            ...,\n",
       "            [-0.0000e+00, -0.0000e+00, -0.0000e+00,  ..., -0.0000e+00,\n",
       "             -0.0000e+00, -0.0000e+00],\n",
       "            [-0.0000e+00, -0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
       "              0.0000e+00, -0.0000e+00],\n",
       "            [-0.0000e+00, -0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
       "              0.0000e+00, -0.0000e+00]],\n",
       "  \n",
       "           ...,\n",
       "  \n",
       "           [[-3.5642e-06, -7.5123e-05, -5.0250e-06,  ..., -1.8895e-05,\n",
       "             -2.9154e-05,  1.3867e-06],\n",
       "            [-9.9580e-05, -1.0616e-04, -1.8593e-04,  ..., -4.8696e-05,\n",
       "             -2.5610e-05, -6.0949e-06],\n",
       "            [ 1.3427e-06, -2.9925e-05,  1.2187e-04,  ..., -4.5247e-05,\n",
       "             -1.0487e-04, -2.6170e-06],\n",
       "            ...,\n",
       "            [ 1.9332e-05,  1.1056e-04,  1.7763e-04,  ..., -7.5136e-05,\n",
       "             -7.9420e-05, -2.6970e-05],\n",
       "            [ 4.5896e-05,  5.0240e-05,  1.8636e-04,  ..., -4.8898e-05,\n",
       "             -1.3647e-04, -1.8245e-05],\n",
       "            [ 6.2492e-06,  6.2988e-05,  6.6625e-05,  ..., -8.0059e-06,\n",
       "             -6.6359e-05, -4.0803e-05]],\n",
       "  \n",
       "           [[ 1.1645e-05, -0.0000e+00,  0.0000e+00,  ..., -2.4396e-07,\n",
       "             -7.8561e-07, -0.0000e+00],\n",
       "            [-3.4233e-07, -0.0000e+00,  0.0000e+00,  ..., -1.4873e-06,\n",
       "             -3.6997e-07,  0.0000e+00],\n",
       "            [ 1.1460e-05, -0.0000e+00,  0.0000e+00,  ..., -5.4442e-07,\n",
       "             -7.1181e-07, -0.0000e+00],\n",
       "            ...,\n",
       "            [-7.7907e-07, -2.4290e-06, -7.7217e-06,  ...,  0.0000e+00,\n",
       "             -1.2438e-06, -5.9370e-08],\n",
       "            [ 2.8016e-07, -1.3987e-06,  4.6623e-06,  ..., -0.0000e+00,\n",
       "              1.0621e-06,  0.0000e+00],\n",
       "            [ 6.4379e-08, -4.2028e-07, -3.7675e-06,  ..., -1.4953e-06,\n",
       "             -2.2957e-06,  1.4341e-07]],\n",
       "  \n",
       "           [[-1.1148e-05,  1.7907e-05, -4.3350e-05,  ..., -8.1241e-06,\n",
       "             -8.3327e-06, -2.1108e-05],\n",
       "            [-0.0000e+00,  4.7013e-05, -3.2085e-05,  ..., -4.1670e-06,\n",
       "              1.2493e-05,  2.4408e-05],\n",
       "            [ 0.0000e+00, -1.2084e-04,  6.8226e-05,  ..., -4.0933e-06,\n",
       "             -1.8638e-05, -5.0922e-05],\n",
       "            ...,\n",
       "            [ 2.4780e-06, -2.1397e-06, -2.3102e-05,  ..., -7.1915e-05,\n",
       "             -2.2374e-05, -5.4675e-05],\n",
       "            [ 1.9172e-07, -3.0027e-05,  4.7586e-06,  ...,  1.0165e-04,\n",
       "             -1.0115e-05, -9.0092e-05],\n",
       "            [ 5.5436e-05,  2.3583e-05, -1.1660e-05,  ..., -9.9705e-05,\n",
       "              2.4567e-05,  3.3145e-05]]]], device='cuda:0',\n",
       "         grad_fn=<MulBackward0>),\n",
       "  tensor([[[[ 1.6368e-05,  2.0156e-05,  2.8951e-05,  ..., -1.3428e-06,\n",
       "             -4.0334e-06, -3.4032e-06],\n",
       "            [ 5.1205e-05,  6.3356e-05,  9.8398e-05,  ...,  3.4409e-05,\n",
       "              2.3139e-06, -2.2898e-07],\n",
       "            [ 3.9134e-05, -6.7333e-05,  1.3269e-04,  ..., -1.9341e-05,\n",
       "             -1.2723e-05, -1.0770e-05],\n",
       "            ...,\n",
       "            [-3.4447e-05,  1.9339e-06, -3.7987e-06,  ..., -3.1164e-05,\n",
       "              1.7412e-05, -1.7150e-05],\n",
       "            [ 9.0298e-06,  6.1362e-06,  4.2181e-06,  ...,  5.8563e-05,\n",
       "              2.5998e-05, -4.1748e-06],\n",
       "            [ 2.1582e-05,  4.6462e-07, -3.9025e-05,  ..., -7.4725e-05,\n",
       "              1.0184e-04,  2.3006e-05]],\n",
       "  \n",
       "           [[-1.0780e-05,  2.3297e-08,  1.6928e-05,  ...,  5.1969e-06,\n",
       "              9.6407e-06,  6.2661e-06],\n",
       "            [ 1.4905e-05, -2.5213e-05,  1.1194e-04,  ...,  1.0439e-05,\n",
       "              8.9724e-06,  4.4074e-06],\n",
       "            [ 2.1174e-05, -1.1374e-04,  1.7124e-04,  ..., -1.8384e-05,\n",
       "             -1.0876e-05, -8.1961e-06],\n",
       "            ...,\n",
       "            [-1.8727e-05,  2.9168e-05, -1.2317e-05,  ..., -8.8751e-05,\n",
       "             -2.6685e-06, -2.6763e-05],\n",
       "            [ 2.1456e-05,  2.6689e-05, -2.5472e-06,  ...,  5.8996e-05,\n",
       "              1.9511e-05,  2.5012e-05],\n",
       "            [ 1.5420e-05,  3.2797e-05, -1.5891e-05,  ..., -1.1256e-04,\n",
       "              1.5579e-05,  6.9293e-05]],\n",
       "  \n",
       "           [[-0.0000e+00, -0.0000e+00, -0.0000e+00,  ..., -0.0000e+00,\n",
       "              0.0000e+00,  0.0000e+00],\n",
       "            [-0.0000e+00, -0.0000e+00, -0.0000e+00,  ..., -0.0000e+00,\n",
       "             -0.0000e+00, -0.0000e+00],\n",
       "            [-0.0000e+00,  0.0000e+00, -0.0000e+00,  ..., -0.0000e+00,\n",
       "             -0.0000e+00, -0.0000e+00],\n",
       "            ...,\n",
       "            [-0.0000e+00,  0.0000e+00,  0.0000e+00,  ..., -0.0000e+00,\n",
       "             -0.0000e+00, -0.0000e+00],\n",
       "            [ 0.0000e+00, -0.0000e+00, -0.0000e+00,  ..., -0.0000e+00,\n",
       "             -0.0000e+00,  0.0000e+00],\n",
       "            [ 0.0000e+00, -0.0000e+00, -0.0000e+00,  ..., -0.0000e+00,\n",
       "             -0.0000e+00,  0.0000e+00]],\n",
       "  \n",
       "           ...,\n",
       "  \n",
       "           [[ 2.1962e-05, -4.3671e-05, -1.1518e-04,  ..., -1.9968e-05,\n",
       "             -2.3813e-05, -3.7817e-06],\n",
       "            [-3.5821e-04, -7.0267e-05, -8.3073e-04,  ..., -1.1530e-04,\n",
       "             -2.3998e-05,  1.4238e-05],\n",
       "            [-1.5167e-04,  1.9299e-04, -7.2259e-04,  ...,  9.5288e-05,\n",
       "              3.2055e-05,  8.1561e-05],\n",
       "            ...,\n",
       "            [-4.4966e-07, -2.7397e-04,  4.2657e-04,  ...,  3.1490e-04,\n",
       "             -1.7704e-05,  1.4137e-04],\n",
       "            [-1.4471e-05, -5.9607e-05,  1.9686e-04,  ..., -7.0307e-05,\n",
       "             -2.2511e-04,  1.6302e-05],\n",
       "            [-6.2804e-05,  3.1123e-05,  2.1976e-04,  ...,  3.5147e-04,\n",
       "             -2.0553e-04, -1.1921e-04]],\n",
       "  \n",
       "           [[ 0.0000e+00, -0.0000e+00, -0.0000e+00,  ...,  0.0000e+00,\n",
       "             -0.0000e+00, -0.0000e+00],\n",
       "            [-0.0000e+00, -0.0000e+00,  0.0000e+00,  ..., -0.0000e+00,\n",
       "             -0.0000e+00, -0.0000e+00],\n",
       "            [ 0.0000e+00, -0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
       "             -0.0000e+00, -0.0000e+00],\n",
       "            ...,\n",
       "            [-0.0000e+00, -0.0000e+00, -0.0000e+00,  ..., -0.0000e+00,\n",
       "             -0.0000e+00, -0.0000e+00],\n",
       "            [ 0.0000e+00, -0.0000e+00, -0.0000e+00,  ...,  0.0000e+00,\n",
       "              0.0000e+00, -0.0000e+00],\n",
       "            [ 0.0000e+00,  0.0000e+00, -0.0000e+00,  ..., -0.0000e+00,\n",
       "              0.0000e+00,  0.0000e+00]],\n",
       "  \n",
       "           [[-1.5864e-05, -1.2305e-05, -3.8253e-05,  ..., -4.1590e-06,\n",
       "             -1.0904e-05, -7.2117e-06],\n",
       "            [-2.4944e-05, -2.7042e-05, -5.9706e-05,  ..., -4.2767e-06,\n",
       "              6.5465e-06,  9.3627e-06],\n",
       "            [ 1.4956e-05, -8.0527e-05, -1.4304e-06,  ...,  1.0304e-06,\n",
       "             -1.8305e-05, -1.0807e-05],\n",
       "            ...,\n",
       "            [-4.2388e-06, -8.8843e-06, -5.7132e-05,  ..., -5.5380e-05,\n",
       "             -1.0678e-05,  5.0854e-06],\n",
       "            [-8.2101e-06, -1.4338e-05, -2.7913e-06,  ...,  1.6324e-05,\n",
       "             -1.0634e-05, -3.4200e-05],\n",
       "            [ 1.9187e-06,  1.2013e-05,  4.2379e-06,  ..., -3.5994e-05,\n",
       "             -1.2405e-05, -1.1910e-06]]]], device='cuda:0',\n",
       "         grad_fn=<MulBackward0>),\n",
       "  tensor([[[[ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
       "              0.0000e+00,  0.0000e+00],\n",
       "            [ 0.0000e+00,  9.7628e-06,  5.2833e-05,  ..., -4.2838e-06,\n",
       "              0.0000e+00,  0.0000e+00],\n",
       "            [ 0.0000e+00,  3.0578e-05,  0.0000e+00,  ...,  1.2043e-06,\n",
       "              0.0000e+00,  0.0000e+00],\n",
       "            ...,\n",
       "            [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  1.2648e-05,\n",
       "              0.0000e+00,  0.0000e+00],\n",
       "            [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
       "              0.0000e+00,  0.0000e+00],\n",
       "            [ 1.3641e-05,  2.7362e-07,  0.0000e+00,  ...,  8.0145e-05,\n",
       "              0.0000e+00,  0.0000e+00]],\n",
       "  \n",
       "           [[-5.5524e-06,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
       "              0.0000e+00,  0.0000e+00],\n",
       "            [ 7.0616e-06,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
       "              0.0000e+00,  7.4168e-06],\n",
       "            [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
       "              0.0000e+00,  0.0000e+00],\n",
       "            ...,\n",
       "            [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
       "              0.0000e+00,  1.8319e-05],\n",
       "            [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
       "              0.0000e+00,  5.1304e-05],\n",
       "            [ 0.0000e+00,  3.2735e-05,  0.0000e+00,  ...,  1.0490e-05,\n",
       "              0.0000e+00,  0.0000e+00]],\n",
       "  \n",
       "           [[ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
       "              0.0000e+00,  0.0000e+00],\n",
       "            [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
       "              0.0000e+00,  0.0000e+00],\n",
       "            [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
       "              0.0000e+00,  0.0000e+00],\n",
       "            ...,\n",
       "            [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
       "              0.0000e+00,  0.0000e+00],\n",
       "            [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
       "              0.0000e+00,  0.0000e+00],\n",
       "            [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
       "              0.0000e+00,  0.0000e+00]],\n",
       "  \n",
       "           ...,\n",
       "  \n",
       "           [[ 1.9870e-05, -3.9387e-05,  0.0000e+00,  ..., -2.1438e-05,\n",
       "              0.0000e+00, -3.4124e-06],\n",
       "            [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
       "              0.0000e+00,  0.0000e+00],\n",
       "            [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
       "              0.0000e+00,  0.0000e+00],\n",
       "            ...,\n",
       "            [ 0.0000e+00, -6.8755e-05,  0.0000e+00,  ..., -1.0625e-04,\n",
       "              0.0000e+00,  0.0000e+00],\n",
       "            [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
       "              0.0000e+00,  0.0000e+00],\n",
       "            [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
       "              0.0000e+00,  0.0000e+00]],\n",
       "  \n",
       "           [[ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
       "              0.0000e+00,  0.0000e+00],\n",
       "            [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
       "              0.0000e+00,  0.0000e+00],\n",
       "            [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
       "              0.0000e+00,  0.0000e+00],\n",
       "            ...,\n",
       "            [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
       "              0.0000e+00,  0.0000e+00],\n",
       "            [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
       "              0.0000e+00,  0.0000e+00],\n",
       "            [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
       "              0.0000e+00,  0.0000e+00]],\n",
       "  \n",
       "           [[-1.0769e-05, -8.2424e-06,  0.0000e+00,  ...,  0.0000e+00,\n",
       "              0.0000e+00, -4.8686e-06],\n",
       "            [-1.6841e-05,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
       "              0.0000e+00,  0.0000e+00],\n",
       "            [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
       "              0.0000e+00,  0.0000e+00],\n",
       "            ...,\n",
       "            [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
       "              0.0000e+00,  0.0000e+00],\n",
       "            [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
       "              0.0000e+00,  0.0000e+00],\n",
       "            [ 0.0000e+00,  9.6124e-06,  0.0000e+00,  ..., -8.4083e-06,\n",
       "              0.0000e+00, -8.2414e-07]]]], device='cuda:0',\n",
       "         grad_fn=<MulBackward0>),\n",
       "  tensor([[[[ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
       "              0.0000e+00,  0.0000e+00],\n",
       "            [ 0.0000e+00,  9.7628e-06,  5.2833e-05,  ..., -4.2838e-06,\n",
       "              0.0000e+00,  0.0000e+00],\n",
       "            [ 0.0000e+00,  3.0578e-05,  0.0000e+00,  ...,  1.2043e-06,\n",
       "              0.0000e+00,  0.0000e+00],\n",
       "            ...,\n",
       "            [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  1.2648e-05,\n",
       "              0.0000e+00,  0.0000e+00],\n",
       "            [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
       "              0.0000e+00,  0.0000e+00],\n",
       "            [ 1.3641e-05,  2.7362e-07,  0.0000e+00,  ...,  8.0145e-05,\n",
       "              0.0000e+00,  0.0000e+00]],\n",
       "  \n",
       "           [[-5.5524e-06,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
       "              0.0000e+00,  0.0000e+00],\n",
       "            [ 7.0616e-06,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
       "              0.0000e+00,  7.4168e-06],\n",
       "            [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
       "              0.0000e+00,  0.0000e+00],\n",
       "            ...,\n",
       "            [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
       "              0.0000e+00,  1.8319e-05],\n",
       "            [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
       "              0.0000e+00,  5.1304e-05],\n",
       "            [ 0.0000e+00,  3.2735e-05,  0.0000e+00,  ...,  1.0490e-05,\n",
       "              0.0000e+00,  0.0000e+00]],\n",
       "  \n",
       "           [[ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
       "              0.0000e+00,  0.0000e+00],\n",
       "            [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
       "              0.0000e+00,  0.0000e+00],\n",
       "            [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
       "              0.0000e+00,  0.0000e+00],\n",
       "            ...,\n",
       "            [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
       "              0.0000e+00,  0.0000e+00],\n",
       "            [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
       "              0.0000e+00,  0.0000e+00],\n",
       "            [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
       "              0.0000e+00,  0.0000e+00]],\n",
       "  \n",
       "           ...,\n",
       "  \n",
       "           [[ 1.9870e-05, -3.9387e-05,  0.0000e+00,  ..., -2.1438e-05,\n",
       "              0.0000e+00, -3.4124e-06],\n",
       "            [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
       "              0.0000e+00,  0.0000e+00],\n",
       "            [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
       "              0.0000e+00,  0.0000e+00],\n",
       "            ...,\n",
       "            [ 0.0000e+00, -6.8755e-05,  0.0000e+00,  ..., -1.0625e-04,\n",
       "              0.0000e+00,  0.0000e+00],\n",
       "            [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
       "              0.0000e+00,  0.0000e+00],\n",
       "            [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
       "              0.0000e+00,  0.0000e+00]],\n",
       "  \n",
       "           [[ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
       "              0.0000e+00,  0.0000e+00],\n",
       "            [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
       "              0.0000e+00,  0.0000e+00],\n",
       "            [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
       "              0.0000e+00,  0.0000e+00],\n",
       "            ...,\n",
       "            [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
       "              0.0000e+00,  0.0000e+00],\n",
       "            [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
       "              0.0000e+00,  0.0000e+00],\n",
       "            [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
       "              0.0000e+00,  0.0000e+00]],\n",
       "  \n",
       "           [[-1.0769e-05, -8.2424e-06,  0.0000e+00,  ...,  0.0000e+00,\n",
       "              0.0000e+00, -4.8686e-06],\n",
       "            [-1.6841e-05,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
       "              0.0000e+00,  0.0000e+00],\n",
       "            [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
       "              0.0000e+00,  0.0000e+00],\n",
       "            ...,\n",
       "            [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
       "              0.0000e+00,  0.0000e+00],\n",
       "            [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
       "              0.0000e+00,  0.0000e+00],\n",
       "            [ 0.0000e+00,  9.6124e-06,  0.0000e+00,  ..., -8.4083e-06,\n",
       "              0.0000e+00, -8.2414e-07]]]], device='cuda:0',\n",
       "         grad_fn=<MulBackward0>),\n",
       "  tensor([[[[ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
       "             -0.0000e+00, -0.0000e+00],\n",
       "            [ 0.0000e+00,  1.7009e-06,  1.3118e-05,  ..., -5.6745e-07,\n",
       "              0.0000e+00,  0.0000e+00],\n",
       "            [ 0.0000e+00,  5.3736e-06,  0.0000e+00,  ...,  1.6338e-07,\n",
       "              0.0000e+00,  0.0000e+00],\n",
       "            ...,\n",
       "            [ 0.0000e+00,  0.0000e+00, -0.0000e+00,  ...,  1.7670e-06,\n",
       "              0.0000e+00,  0.0000e+00],\n",
       "            [ 0.0000e+00,  0.0000e+00, -0.0000e+00,  ...,  0.0000e+00,\n",
       "              0.0000e+00,  0.0000e+00],\n",
       "            [ 3.3702e-06,  4.3453e-08,  0.0000e+00,  ...,  2.1425e-05,\n",
       "              0.0000e+00,  0.0000e+00]],\n",
       "  \n",
       "           [[ 1.0116e-06, -0.0000e+00, -0.0000e+00,  ...,  0.0000e+00,\n",
       "              0.0000e+00,  0.0000e+00],\n",
       "            [-1.9974e-06, -0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
       "              0.0000e+00,  1.9001e-06],\n",
       "            [-0.0000e+00, -0.0000e+00, -0.0000e+00,  ...,  0.0000e+00,\n",
       "              0.0000e+00,  0.0000e+00],\n",
       "            ...,\n",
       "            [-0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
       "              0.0000e+00,  6.3695e-06],\n",
       "            [-0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
       "              0.0000e+00,  1.8835e-05],\n",
       "            [ 0.0000e+00,  7.1130e-06,  0.0000e+00,  ...,  2.1356e-06,\n",
       "              0.0000e+00,  0.0000e+00]],\n",
       "  \n",
       "           [[-0.0000e+00, -0.0000e+00, -0.0000e+00,  ..., -0.0000e+00,\n",
       "             -0.0000e+00, -0.0000e+00],\n",
       "            [-0.0000e+00, -0.0000e+00, -0.0000e+00,  ..., -0.0000e+00,\n",
       "             -0.0000e+00, -0.0000e+00],\n",
       "            [-0.0000e+00, -0.0000e+00, -0.0000e+00,  ..., -0.0000e+00,\n",
       "             -0.0000e+00, -0.0000e+00],\n",
       "            ...,\n",
       "            [-0.0000e+00, -0.0000e+00, -0.0000e+00,  ..., -0.0000e+00,\n",
       "             -0.0000e+00, -0.0000e+00],\n",
       "            [-0.0000e+00, -0.0000e+00, -0.0000e+00,  ..., -0.0000e+00,\n",
       "             -0.0000e+00, -0.0000e+00],\n",
       "            [-0.0000e+00, -0.0000e+00, -0.0000e+00,  ..., -0.0000e+00,\n",
       "             -0.0000e+00, -0.0000e+00]],\n",
       "  \n",
       "           ...,\n",
       "  \n",
       "           [[ 5.0616e-07,  1.4258e-07, -0.0000e+00,  ...,  4.4410e-07,\n",
       "             -0.0000e+00, -2.2408e-09],\n",
       "            [ 0.0000e+00, -0.0000e+00, -0.0000e+00,  ..., -0.0000e+00,\n",
       "             -0.0000e+00, -0.0000e+00],\n",
       "            [ 0.0000e+00, -0.0000e+00, -0.0000e+00,  ..., -0.0000e+00,\n",
       "             -0.0000e+00, -0.0000e+00],\n",
       "            ...,\n",
       "            [-0.0000e+00,  8.8168e-06,  0.0000e+00,  ...,  1.1943e-05,\n",
       "             -0.0000e+00, -0.0000e+00],\n",
       "            [-0.0000e+00, -0.0000e+00,  0.0000e+00,  ..., -0.0000e+00,\n",
       "             -0.0000e+00, -0.0000e+00],\n",
       "            [-0.0000e+00, -0.0000e+00, -0.0000e+00,  ..., -0.0000e+00,\n",
       "             -0.0000e+00, -0.0000e+00]],\n",
       "  \n",
       "           [[ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
       "              0.0000e+00,  0.0000e+00],\n",
       "            [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
       "              0.0000e+00,  0.0000e+00],\n",
       "            [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
       "              0.0000e+00,  0.0000e+00],\n",
       "            ...,\n",
       "            [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
       "              0.0000e+00,  0.0000e+00],\n",
       "            [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
       "              0.0000e+00,  0.0000e+00],\n",
       "            [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
       "              0.0000e+00,  0.0000e+00]],\n",
       "  \n",
       "           [[ 2.4459e-07,  4.2255e-07, -0.0000e+00,  ..., -0.0000e+00,\n",
       "             -0.0000e+00,  1.6849e-07],\n",
       "            [ 5.8013e-07, -0.0000e+00, -0.0000e+00,  ..., -0.0000e+00,\n",
       "             -0.0000e+00, -0.0000e+00],\n",
       "            [-0.0000e+00, -0.0000e+00, -0.0000e+00,  ..., -0.0000e+00,\n",
       "             -0.0000e+00, -0.0000e+00],\n",
       "            ...,\n",
       "            [-0.0000e+00, -0.0000e+00, -0.0000e+00,  ..., -0.0000e+00,\n",
       "             -0.0000e+00, -0.0000e+00],\n",
       "            [-0.0000e+00, -0.0000e+00, -0.0000e+00,  ..., -0.0000e+00,\n",
       "             -0.0000e+00, -0.0000e+00],\n",
       "            [-0.0000e+00,  1.2265e-07, -0.0000e+00,  ...,  2.1790e-07,\n",
       "             -0.0000e+00, -1.5740e-08]]]], device='cuda:0',\n",
       "         grad_fn=<MulBackward0>),\n",
       "  tensor([[[[-6.6446e-06,  7.8239e-06,  1.3499e-05,  ...,  2.6019e-06,\n",
       "              2.7566e-06, -3.0843e-07],\n",
       "            [-5.5662e-06, -1.3313e-05, -8.5672e-06,  ...,  4.4158e-06,\n",
       "              1.9320e-06,  3.8517e-07],\n",
       "            [-5.3998e-06,  3.4021e-05,  2.1298e-05,  ...,  4.0359e-06,\n",
       "              1.5859e-06,  3.7613e-07],\n",
       "            ...,\n",
       "            [-3.7038e-04, -1.3911e-04, -1.2080e-04,  ..., -6.6532e-07,\n",
       "              1.8846e-05, -1.9139e-05],\n",
       "            [-2.0486e-04, -1.9950e-04, -5.9382e-05,  ...,  2.8759e-05,\n",
       "              1.3267e-06, -9.5623e-06],\n",
       "            [-1.4602e-04, -1.9886e-05, -9.9686e-05,  ..., -1.0745e-05,\n",
       "              1.5539e-06, -1.7817e-05]]]], device='cuda:0',\n",
       "         grad_fn=<MulBackward0>)],\n",
       " 'pp': [tensor([[ 1.2712e-02, -1.3572e-02,  3.4755e-04,  3.3058e-03, -7.6231e-03,\n",
       "           -2.0908e-03, -1.1769e-04, -3.4941e-03,  3.9383e-04, -9.1561e-06]],\n",
       "         device='cuda:0', grad_fn=<MulBackward0>),\n",
       "  tensor([ 0.0166, -0.0076,  0.0008, -0.0028, -0.0052, -0.0175,  0.0260, -0.0045,\n",
       "          -0.0115,  0.0045], device='cuda:0', grad_fn=<MulBackward0>),\n",
       "  tensor([[ 2.2683e-03, -5.3442e-04,  5.5802e-04, -9.1821e-04, -7.1378e-03,\n",
       "           -1.9298e-02,  9.8239e-03, -6.0206e-03, -3.0406e-05,  3.1940e-03]],\n",
       "         device='cuda:0', grad_fn=<MulBackward0>),\n",
       "  tensor([ 0.0039, -0.0204, -0.0020,  0.0019,  0.0757, -0.0010,  0.0076, -0.0560,\n",
       "          -0.0333, -0.0136], device='cuda:0', grad_fn=<MulBackward0>),\n",
       "  tensor([[ 2.4273e-03, -6.5776e-03, -1.3617e-03,  4.6964e-05,  3.6166e-02,\n",
       "           -5.3230e-04,  4.0438e-03, -1.4280e-03, -1.7797e-02, -8.9134e-03]],\n",
       "         device='cuda:0', grad_fn=<MulBackward0>),\n",
       "  tensor([-0.0333,  0.0220,  0.0019, -0.0041,  0.0192,  0.0100,  0.0097, -0.0098,\n",
       "          -0.0161,  0.0123], device='cuda:0', grad_fn=<MulBackward0>),\n",
       "  tensor([[-0.0103,  0.0120,  0.0013, -0.0024,  0.0130,  0.0046,  0.0051, -0.0043,\n",
       "           -0.0250,  0.0087]], device='cuda:0', grad_fn=<MulBackward0>),\n",
       "  tensor([-0.0242,  0.0142, -0.0056,  0.0216, -0.0046, -0.0133, -0.0052,  0.0215,\n",
       "           0.0044], device='cuda:0', grad_fn=<MulBackward0>)],\n",
       " 'final': [tensor([4.6298e-07, 1.4994e-05, 5.1979e-03, 1.2261e-04, 1.2002e-05, 1.7589e-07,\n",
       "          1.3774e-04, 3.1046e-04, 1.8554e-05, 3.3863e-07, 3.6423e-07, 4.2984e-07,\n",
       "          1.5641e-03, 9.0317e-04, 2.2509e-05, 1.3171e-05, 2.5683e-05, 9.9109e-01,\n",
       "          1.0909e-06, 8.5566e-07, 1.1398e-06, 4.6154e-05, 2.3301e-04, 2.8695e-04],\n",
       "         device='cuda:0', grad_fn=<SoftmaxBackward0>),\n",
       "  tensor([ 2.0400e-02, -1.1330e-02,  4.1423e-02,  2.8156e-02,  1.2067e-04,\n",
       "           1.1270e-02,  7.7582e-05,  5.2287e-03,  8.8389e-03, -3.9165e-03,\n",
       "           1.0395e-02,  2.1565e-02, -3.2942e-03,  2.3588e-02,  7.2335e-03,\n",
       "           5.1596e-03,  5.9631e-03,  9.2831e-03,  1.4098e-03,  5.0962e-03,\n",
       "          -2.8734e-02,  8.6368e-03, -8.8362e-03, -4.9206e-03, -2.9363e-02,\n",
       "          -2.2769e-02, -5.3586e-03,  2.8459e-02, -1.3390e-02,  2.0224e-02,\n",
       "           1.7842e-02,  2.2830e-02,  4.5272e-02,  7.5750e-05,  4.4960e-02,\n",
       "           3.4360e-02,  4.6375e-03, -3.0035e-02, -3.7828e-04,  5.1285e-02,\n",
       "          -6.2911e-04, -4.7611e-03,  2.4398e-02,  1.1472e-03,  3.5707e-03,\n",
       "           4.8383e-03,  2.0369e-02, -1.0674e-02,  2.3296e-03,  3.3522e-02,\n",
       "           6.4032e-03, -2.3448e-02, -2.2152e-02, -9.9111e-03,  3.9625e-02,\n",
       "           8.0608e-03,  3.2836e-02,  2.8693e-02,  1.8021e-02,  2.6453e-02,\n",
       "           1.9018e-02,  1.8128e-02,  2.1366e-02, -1.4762e-02,  2.5620e-02,\n",
       "          -5.7815e-03,  2.3385e-02,  2.2414e-03, -9.9564e-04,  2.2522e-03,\n",
       "           2.2501e-02,  4.4459e-02,  4.6346e-02,  4.5870e-03,  1.3532e-02,\n",
       "           4.0152e-03, -2.2361e-02,  3.8921e-02,  1.8948e-02,  2.4121e-03,\n",
       "           1.8348e-02,  1.5932e-02,  4.3990e-03,  4.3033e-02,  1.2349e-02,\n",
       "           2.6270e-02,  1.9349e-02,  1.5353e-02,  1.8464e-02,  1.2481e-02,\n",
       "          -1.1492e-02, -3.3889e-02,  1.0980e-02, -1.4156e-02, -3.9768e-03,\n",
       "           2.4065e-04,  1.7224e-02,  2.4690e-02,  2.1422e-02,  1.9661e-02],\n",
       "         device='cuda:0', grad_fn=<MulBackward0>),\n",
       "  tensor([ 2.2752e-07, -2.7753e-05,  0.0000e+00,  8.9999e-05,  7.9627e-10,\n",
       "           3.3955e-05,  1.7610e-05,  0.0000e+00,  4.4826e-08, -7.9002e-03,\n",
       "           5.3841e-03,  1.0297e-04, -2.4690e-03,  1.0061e-07,  1.1873e-03,\n",
       "           1.9570e-04,  5.3957e-08,  3.6905e-03,  1.8301e-04,  1.0141e-04,\n",
       "          -3.6242e-06,  4.2644e-04, -5.4355e-03, -5.6160e-03, -2.4618e-03,\n",
       "          -1.0293e-03, -4.9004e-04,  4.4487e-03, -3.0649e-06,  3.9080e-04,\n",
       "           0.0000e+00,  3.6650e-05,  2.7112e-04, -2.0922e-05,  3.9910e-04,\n",
       "           1.9542e-05,  2.1352e-07, -9.6011e-06, -2.3682e-07,  0.0000e+00,\n",
       "          -3.3703e-04, -1.2525e-03,  1.4398e-06,  9.6510e-04,  2.2961e-03,\n",
       "           2.2301e-07,  1.9077e-03, -1.4616e-03,  0.0000e+00,  0.0000e+00,\n",
       "           1.0270e-03, -5.1889e-08, -8.9633e-04, -2.3856e-06,  1.3759e-07,\n",
       "           0.0000e+00,  2.3101e-04,  1.4981e-06,  0.0000e+00,  3.9029e-05,\n",
       "           5.0203e-08,  1.4555e-06,  6.9489e-08, -2.8527e-03,  0.0000e+00,\n",
       "          -7.8305e-05,  1.0122e-03,  1.6429e-07, -4.5935e-06,  1.0429e-05,\n",
       "           4.1147e-05,  0.0000e+00,  0.0000e+00,  6.9563e-05,  4.6617e-04,\n",
       "           2.0350e-04, -9.9271e-03,  0.0000e+00,  5.3562e-03,  4.2142e-05,\n",
       "           2.9885e-07,  9.6179e-03,  3.1373e-03,  5.4646e-07,  1.5618e-07,\n",
       "           4.7640e-04,  0.0000e+00,  9.1807e-04,  0.0000e+00,  0.0000e+00,\n",
       "          -9.2475e-03, -1.1674e-06,  0.0000e+00, -1.5645e-05, -2.6983e-03,\n",
       "           6.1830e-05,  1.7569e-05,  7.2485e-07,  7.5575e-07,  3.5590e-04],\n",
       "         device='cuda:0', grad_fn=<MulBackward0>),\n",
       "  tensor([-6.5790e-04, -4.0155e-03, -1.0379e-02, -4.1865e-05, -1.3465e-03,\n",
       "           1.2141e-03,  1.9604e-03,  1.7856e-04,  1.5591e-03, -1.0225e-03,\n",
       "           1.2644e-03,  1.3605e-03, -3.2476e-03,  1.8252e-02, -5.2775e-04,\n",
       "           5.4172e-04, -4.7370e-04,  2.7145e-03,  4.2995e-03, -4.6292e-05,\n",
       "           1.0786e-02, -1.3914e-02,  8.5430e-04, -2.7457e-04,  1.4775e-04,\n",
       "           5.2184e-04,  3.1765e-03, -8.3090e-06, -6.6276e-03,  1.8320e-03,\n",
       "           1.3375e-03,  8.7836e-04, -4.5775e-03, -4.1386e-03, -7.3824e-05,\n",
       "           8.0040e-05,  3.9935e-04,  7.7245e-03, -2.5026e-04,  1.2847e-02,\n",
       "          -1.7194e-03, -7.3594e-04,  4.0183e-03,  1.9110e-03, -1.6994e-02,\n",
       "          -1.8945e-04,  1.1738e-03,  2.0742e-03, -2.6780e-03,  5.8797e-03,\n",
       "          -1.8430e-03, -7.9906e-04, -1.1180e-03, -5.6017e-04, -3.9686e-03,\n",
       "          -2.8203e-05,  6.7644e-03,  3.6153e-04,  2.6598e-02,  6.2821e-05,\n",
       "           1.5794e-05, -4.3961e-03, -2.9871e-04,  8.1208e-04,  1.8778e-04,\n",
       "           2.0972e-02, -5.0437e-04, -6.6132e-03, -7.5674e-03, -1.0396e-02,\n",
       "          -4.8323e-03, -6.6387e-03,  1.0527e-02, -5.1388e-05,  3.9866e-03,\n",
       "          -2.6192e-03,  5.2054e-03, -9.3989e-03,  1.0484e-02,  5.9522e-03,\n",
       "           2.1639e-04,  5.5734e-03,  8.7214e-04,  1.2972e-02,  4.3601e-03,\n",
       "           5.7631e-03, -1.6577e-02, -1.0775e-02,  3.2534e-03,  9.5255e-03,\n",
       "          -1.3702e-03,  3.1278e-04,  1.0539e-03,  3.2723e-03,  1.5205e-02,\n",
       "           3.7750e-04,  3.3525e-03,  1.4710e-03, -7.3185e-04,  3.1948e-03,\n",
       "          -1.0922e-02,  5.6455e-03,  2.8781e-03, -3.0315e-03,  3.0171e-04,\n",
       "          -5.3731e-03, -3.5297e-03, -6.9262e-04, -2.4939e-04,  8.8716e-04,\n",
       "           2.3883e-03, -1.2928e-04, -2.7104e-03,  1.6720e-03, -1.1048e-03,\n",
       "           7.5042e-04, -1.6706e-03, -9.3003e-04, -4.5750e-03,  1.2206e-03,\n",
       "          -1.2583e-02,  9.4085e-03, -1.1154e-03,  9.4300e-04,  6.3626e-03,\n",
       "          -2.4809e-05,  1.3072e-03,  9.6478e-03,  3.0713e-03,  3.7655e-04,\n",
       "           1.7710e-02,  1.1153e-02,  5.0185e-04,  1.0733e-03,  3.5894e-03,\n",
       "           7.7613e-03, -1.5532e-03,  2.1666e-03,  1.5819e-03, -8.7382e-03,\n",
       "           1.6434e-02,  3.3483e-05, -3.6335e-04, -1.5367e-03, -2.0821e-03,\n",
       "          -9.0273e-04,  4.8145e-03, -1.0840e-03,  5.2930e-04, -3.0750e-03,\n",
       "           1.1137e-02,  1.1488e-03, -8.4650e-03, -2.2273e-05, -6.4940e-04,\n",
       "           6.4266e-04, -9.9093e-03,  9.6769e-04,  2.5904e-03,  5.1933e-03,\n",
       "           1.6898e-03, -2.3086e-04,  4.2845e-03, -1.3103e-02,  1.3827e-02,\n",
       "           7.1428e-04,  7.3389e-03,  9.8310e-05, -1.6767e-03, -5.7379e-03,\n",
       "           3.0207e-03, -2.0236e-03,  5.4371e-05, -8.2636e-04,  1.2175e-03,\n",
       "           9.2967e-04,  3.2135e-03,  1.2285e-02,  1.5589e-03,  5.4644e-03,\n",
       "           7.9689e-04,  9.2962e-04,  3.9853e-03, -2.1182e-03, -1.4264e-03,\n",
       "          -7.2698e-03,  3.1393e-03,  1.1025e-05,  2.0069e-04, -1.5818e-03,\n",
       "          -1.3645e-03,  7.0931e-05, -6.8951e-03,  1.4834e-03,  1.6658e-03,\n",
       "          -1.3096e-04, -1.6776e-04, -4.9677e-03, -6.1139e-04, -1.2687e-02,\n",
       "          -3.7860e-03,  2.6172e-03,  1.4127e-03, -4.8228e-03, -6.0929e-04,\n",
       "          -3.6441e-04, -2.8654e-04,  5.3246e-03, -5.8198e-03, -2.4955e-02,\n",
       "           6.0481e-03, -1.8339e-03,  5.7750e-04,  1.1585e-02,  3.9685e-03,\n",
       "          -2.1454e-03,  3.0235e-05,  1.4814e-03, -1.7426e-03,  8.4906e-05,\n",
       "          -1.0174e-02,  5.9440e-04,  6.8587e-04, -1.4682e-04, -1.5114e-03,\n",
       "           1.4258e-03,  1.1377e-04, -9.4196e-03, -1.6774e-05, -1.7611e-02,\n",
       "          -7.2405e-04, -1.1387e-03,  2.4734e-03,  1.3571e-04,  3.1958e-04,\n",
       "           1.3179e-02,  2.9928e-04,  9.7085e-04,  1.1896e-03, -5.9829e-07,\n",
       "           4.1310e-03, -2.6409e-03,  5.1840e-03,  1.0495e-04,  7.1742e-03,\n",
       "           5.8052e-03, -5.5053e-03,  8.8946e-04,  3.1299e-03, -7.9894e-05,\n",
       "          -9.3315e-03,  4.0622e-04,  1.0994e-03, -2.9362e-03, -8.6446e-04,\n",
       "          -1.8294e-03, -5.3971e-03,  1.7035e-03, -1.3170e-04, -8.2136e-03,\n",
       "           1.1373e-03,  4.1822e-03, -6.3246e-03,  1.3315e-02,  8.6334e-04,\n",
       "           7.9168e-03, -7.1719e-03,  1.0792e-03,  7.0813e-03,  1.7103e-02,\n",
       "          -9.9405e-03, -1.7289e-03,  6.0025e-04, -4.7136e-04, -7.7019e-04,\n",
       "          -1.9044e-04,  3.6945e-05,  1.4385e-03, -2.9404e-04, -3.2799e-03,\n",
       "          -5.6928e-03,  4.1668e-03,  5.5305e-07, -2.7786e-03,  3.8988e-03,\n",
       "          -1.7364e-03, -4.7830e-03,  5.3113e-05,  1.4565e-04,  5.9939e-03,\n",
       "          -1.4726e-02,  1.9360e-03,  4.3654e-03, -6.6253e-05, -1.0908e-05,\n",
       "           1.4224e-03, -5.0519e-03, -2.7356e-03,  2.9777e-03,  5.7436e-04,\n",
       "           3.3090e-03,  1.6761e-03,  2.0907e-03, -6.7697e-05,  1.4827e-04,\n",
       "          -7.7913e-04,  1.3472e-03, -2.4682e-03, -1.4449e-03, -1.7638e-03,\n",
       "           1.2015e-03, -1.5125e-03, -7.1553e-04, -2.5198e-03, -2.9389e-04,\n",
       "           5.7604e-03,  2.9094e-03,  4.5928e-03,  2.3437e-03, -9.1199e-03,\n",
       "           1.1659e-03,  2.3537e-03,  2.9062e-04,  7.1489e-03, -1.8946e-03,\n",
       "          -2.0288e-03,  1.3067e-02,  1.5102e-03, -2.9317e-03, -3.0742e-03,\n",
       "          -2.1096e-04,  2.0543e-03, -5.0307e-03,  1.4195e-03, -1.8235e-03,\n",
       "           6.4955e-04,  2.6503e-03, -4.3450e-04, -1.9226e-03, -1.4619e-03,\n",
       "          -9.1021e-04, -3.0653e-03,  3.4520e-04, -1.7974e-03, -4.6365e-04,\n",
       "          -4.7909e-03, -8.8782e-04,  1.9451e-03, -5.2587e-03,  3.9768e-03,\n",
       "           3.1978e-03,  5.3606e-03,  3.5866e-05,  2.4151e-03, -1.3441e-04,\n",
       "          -1.4401e-03,  1.0413e-02,  2.7287e-03, -2.0127e-03,  3.2863e-03,\n",
       "           6.3066e-04,  2.8072e-04,  5.9913e-05,  6.7336e-05, -2.9904e-04,\n",
       "           8.0546e-04, -3.0231e-04,  2.1726e-03, -4.1988e-03,  2.2141e-03,\n",
       "           3.6461e-03,  4.9938e-03, -4.4205e-03, -2.4475e-03,  1.5559e-02,\n",
       "          -1.2575e-03, -1.9177e-02,  2.1731e-03,  6.4414e-03, -3.0383e-05,\n",
       "          -4.9986e-04, -4.5658e-04, -4.7342e-03, -2.6629e-04, -5.0899e-03,\n",
       "          -8.6118e-03,  9.3617e-04, -7.0377e-03, -3.6948e-04,  5.6877e-04,\n",
       "          -4.7419e-03,  1.6249e-03, -3.0893e-03,  8.5618e-04,  2.5560e-04,\n",
       "          -2.2321e-03,  3.2529e-03,  8.4183e-03, -9.7935e-03, -3.9910e-03,\n",
       "          -1.5288e-02,  1.2254e-03,  2.7359e-03,  4.6275e-04, -2.7158e-03,\n",
       "          -1.4463e-04, -5.8177e-03,  4.4358e-04, -6.5583e-04, -3.6649e-04,\n",
       "          -8.7842e-03,  2.5419e-03, -1.8447e-02,  2.6224e-04, -1.6874e-02,\n",
       "          -5.8413e-03, -1.0997e-02,  1.0710e-02,  3.0183e-04, -4.8334e-03,\n",
       "          -6.4105e-04, -1.3618e-03, -1.5911e-05, -7.0339e-04, -2.2094e-03,\n",
       "           4.5151e-03,  3.0170e-03, -3.6486e-03,  1.0196e-02, -7.4633e-03,\n",
       "           1.0833e-02, -1.8267e-04,  1.0414e-02,  5.0697e-04,  3.0853e-03,\n",
       "           4.8292e-03, -3.8590e-03, -1.4777e-02, -1.4195e-03,  1.3345e-03,\n",
       "          -3.3583e-05,  4.6091e-03, -7.3396e-04,  1.8466e-04, -1.6909e-03,\n",
       "          -8.6247e-03,  8.8203e-04,  2.7681e-03,  2.8950e-03,  7.7307e-03,\n",
       "           1.2269e-02, -7.1973e-03, -1.4487e-02,  1.1648e-03,  1.9203e-03,\n",
       "           1.6290e-04, -8.2569e-04, -3.3605e-03, -4.5312e-04, -1.9910e-03,\n",
       "           1.1141e-02,  2.7553e-03,  2.2307e-03, -1.7244e-03,  1.0531e-03,\n",
       "           5.0570e-03,  2.6323e-03, -1.8536e-02, -1.4255e-02,  1.1110e-03,\n",
       "           8.8809e-03, -5.5330e-04, -6.5791e-03, -7.0143e-04, -1.1284e-03,\n",
       "           4.0431e-04, -1.3938e-03,  3.8541e-04,  1.9811e-03,  1.4487e-03,\n",
       "          -5.9378e-03, -1.8225e-03,  1.2021e-03, -1.0229e-03, -4.4266e-03,\n",
       "           3.1200e-03, -4.2102e-04, -2.3895e-04, -1.3920e-04,  4.1722e-03,\n",
       "          -8.4363e-04, -2.6089e-03, -5.2284e-03, -5.4391e-04, -5.7436e-03,\n",
       "           3.5016e-03,  3.0980e-03, -1.9938e-03, -3.4227e-05,  1.4385e-05,\n",
       "          -3.8601e-03, -4.2136e-03, -1.9336e-03,  1.0674e-02,  2.4112e-03,\n",
       "          -5.8089e-03,  1.5980e-04,  8.6732e-06,  2.8827e-03,  1.6074e-03,\n",
       "           1.8363e-03, -6.6939e-04,  1.9010e-02, -3.8947e-02,  6.7632e-04,\n",
       "           4.1824e-02, -1.2673e-02, -4.5025e-02, -5.9237e-04, -1.2325e-02,\n",
       "           7.9465e-03, -3.5809e-03], device='cuda:0', grad_fn=<MulBackward0>)]}"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample = next(iter(dataloader_test))\n",
    "\n",
    "R_dict = lrp_eps.evaluate(sample)\n",
    "R_dict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Analyze the LRP Results "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "axes don't match array",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_22061/453619429.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mimg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msample\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'image'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msqueeze\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mimg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtranspose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxes\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0mpp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msample\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'process_parameters'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0mlabel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msample\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'label'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<__array_function__ internals>\u001b[0m in \u001b[0;36mtranspose\u001b[0;34m(*args, **kwargs)\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/multiclassMeltpool/lib/python3.7/site-packages/numpy/core/fromnumeric.py\u001b[0m in \u001b[0;36mtranspose\u001b[0;34m(a, axes)\u001b[0m\n\u001b[1;32m    658\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    659\u001b[0m     \"\"\"\n\u001b[0;32m--> 660\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_wrapfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'transpose'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxes\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    661\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    662\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/multiclassMeltpool/lib/python3.7/site-packages/numpy/core/fromnumeric.py\u001b[0m in \u001b[0;36m_wrapfunc\u001b[0;34m(obj, method, *args, **kwds)\u001b[0m\n\u001b[1;32m     55\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     56\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 57\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mbound\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     58\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     59\u001b[0m         \u001b[0;31m# A TypeError occurs if the object does have such a method in its\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: axes don't match array"
     ]
    }
   ],
   "source": [
    "sample = next(iter(dataloader_test))\n",
    "\n",
    "img = sample['image'].numpy().squeeze()\n",
    "img = np.transpose(img, axes=[1,2,0])\n",
    "pp = sample['process_parameters'].numpy()\n",
    "label = sample['label'].item()\n",
    "R_img_list = R_dict[\"image\"]\n",
    "R_img = R_img_list[-1].cpu().detach().numpy().squeeze()\n",
    "R_img = np.transpose(R_img, axes=[1,2,0])\n",
    "\n",
    "R_pp_list = R_dict[\"pp\"]\n",
    "R_pp = R_pp_list[-1]\n",
    "\n",
    "images = sample['image']\n",
    "process_parameters = sample['process_parameters']\n",
    "images = images.to(device=device, dtype=torch.float)\n",
    "process_parameters = process_parameters.to(device=device, dtype=torch.float)\n",
    "with torch.set_grad_enabled(False):\n",
    "    outputs = model(images, process_parameters)\n",
    "    _, preds = torch.max(outputs, 1)\n",
    "        \n",
    "fig, axs = plt.subplot_mosaic([['left', 'right'],['bottom', 'bottom']])\n",
    "axs['left'].imshow(img)\n",
    "# axs['left'].title.set_text(\"GT: \" + str(label) + \", Pred: \" + str(preds.item()))\n",
    "axs['left'].title.set_text(\"Original Image\")\n",
    "axs['left'].set_xticks([])\n",
    "axs['left'].set_yticks([])\n",
    "axs['left'].set_xticklabels([])\n",
    "axs['left'].set_yticklabels([])\n",
    "\n",
    "heatmap = axs['right'].imshow(R_img)\n",
    "cbar = fig.colorbar(heatmap, ax=axs['right'])\n",
    "cbar.ax.yaxis.set_offset_position('left')\n",
    "cbar.update_ticks()\n",
    "axs['right'].title.set_text('Image Relevance')\n",
    "axs['right'].set_xticks([])\n",
    "axs['right'].set_yticks([])\n",
    "axs['right'].set_xticklabels([])\n",
    "axs['right'].set_yticklabels([])\n",
    "\n",
    "axs['bottom'].scatter(np.arange(9), R_pp.cpu().detach().numpy(), color=\"blue\", marker=\"d\")\n",
    "axs['bottom'].set_ylabel(\"Relevance\",fontsize=14)\n",
    "# axs['bottom'].set_ylabel(\"Relevance\",color=\"blue\",fontsize=14)\n",
    "axs['bottom'].axhline(0, linestyle='dashed')\n",
    "\n",
    "axs['bottom'].title.set_text('Parameter Relevance')\n",
    "pp_labels = ('Power','Speed','x_dir', 'y_dir','Acceleration','Energy Density','Heating',\n",
    "             'Turning', 'Residual Heat')\n",
    "axs['bottom'].set_xticks(np.arange(9))\n",
    "axs['bottom'].set_xticklabels(pp_labels, rotation=80, fontdict={'fontsize': 12})\n",
    "fig.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Save LRP outputs to file --- FIXME"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# LRP-Epsilon\n",
    "counter = 0\n",
    "for sample in dataloader:\n",
    "    if np.mod(counter, 500) == 0:\n",
    "        print(counter, '/', len(dataloader))\n",
    "    counter += 1\n",
    "    \n",
    "    pp = sample['process_parameters']\n",
    "    \n",
    "    img_name = sample['img_name'][0]\n",
    "    idx = img_name.find('Base')\n",
    "    if idx == -1:\n",
    "        idx = img_name.find('MPA')\n",
    "    img_name1 = img_name[idx:]\n",
    "    if os.path.exists('./analysis/lrp_epsilon_combined_sigmoid_side_by_side/' + img_name1):\n",
    "        continue\n",
    "        \n",
    "    R_dict =lrp_combined.evaluate(sample)\n",
    "\n",
    "    img = sample['image']\n",
    "    img = img.numpy().squeeze()\n",
    "    img = np.uint8(255*img)\n",
    "    img = np.stack((img,img,img), 2)\n",
    "    \n",
    "    label = sample['label'].item()\n",
    "\n",
    "    R_img_list = R_dict[\"image\"]\n",
    "    R_img = R_img_list[-1]\n",
    "\n",
    "    R_pp_list = R_dict[\"pp\"]\n",
    "    R_pp = R_pp_list[-1]\n",
    "\n",
    "    # Original Image\n",
    "    img_name = sample['img_name'][0]\n",
    "    orig_img = cv2.imread(img_name)\n",
    "    # Get image name\n",
    "    idx = img_name.find('Base')\n",
    "    if idx == -1:\n",
    "        idx = img_name.find('MPA')\n",
    "    img_name1 = img_name[idx:]\n",
    "\n",
    "    images = sample['image']\n",
    "    process_parameters = sample['process_parameters']\n",
    "    images = images.to(device=device, dtype=torch.float)\n",
    "    process_parameters = process_parameters.to(device=device, dtype=torch.float)\n",
    "    with torch.set_grad_enabled(False):\n",
    "        outputs = model(images, process_parameters)\n",
    "        _, preds = torch.max(outputs, 1)\n",
    "    \n",
    "    fig, axs = plt.subplot_mosaic([['left', 'right'],['bottom', 'bottom']])\n",
    "    axs['left'].matshow(img)\n",
    "    axs['left'].title.set_text(\"GT: \" + str(label) + \", Pred: \" + str(preds.item()))\n",
    "    axs['left'].set_xticks([])\n",
    "    axs['left'].set_yticks([])\n",
    "    axs['left'].set_xticklabels([])\n",
    "    axs['left'].set_yticklabels([])\n",
    "\n",
    "    heatmap = axs['right'].matshow(R_img.cpu().detach().numpy().squeeze())\n",
    "    cbar = fig.colorbar(heatmap, ax=axs['right'])\n",
    "    axs['right'].title.set_text('Image Relevance')\n",
    "    axs['right'].set_xticks([])\n",
    "    axs['right'].set_yticks([])\n",
    "    axs['right'].set_xticklabels([])\n",
    "    axs['right'].set_yticklabels([])\n",
    "\n",
    "    axs['bottom'].bar(np.arange(12), R_pp.cpu().detach().numpy(), color=\"blue\")\n",
    "    axs['bottom'].set_ylabel(\"Relevance\",color=\"blue\",fontsize=14)\n",
    "    \n",
    "    ax2 = axs['bottom'].twinx()\n",
    "    ax2.scatter(np.arange(12), pp, c=\"orange\", marker=\"d\")\n",
    "    ax2.set_yticks([-1.0, -0.5, 0, 0.5, 1])\n",
    "    ax2.set_ylabel(\"PP Value\",color=\"orange\",fontsize=14)\n",
    "    axs['bottom'].title.set_text('Parameter Relevance')\n",
    "    pp_labels = ('P','V','a', 'Energy Density','isAccel','isSpeeding','isSlowing',\n",
    "             'isTurning', 'isHeating','isCooling','closeness1', 'closeness2')\n",
    "    axs['bottom'].set_xticks(np.arange(12))\n",
    "    axs['bottom'].set_xticklabels(pp_labels, rotation=90)\n",
    "    plt.tight_layout()\n",
    "    fig.savefig('./analysis/lrp_epsilon_combined_sigmoid_side_by_side/' + img_name1)\n",
    "    if (label != preds.item()):\n",
    "        fig.savefig('./analysis/lrp_epsilon_combined_sigmoid_side_by_side_incorrect/' + img_name1)\n",
    "    plt.close(fig)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Analyze the Process Parameters "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████| 103081/103081 [22:46<00:00, 75.46it/s]\n"
     ]
    }
   ],
   "source": [
    "# LRP-Epsilon\n",
    "pp_array = np.zeros((NUM_MELT_POOL_CLASSES, NUM_PROCESS_PARAM))\n",
    "ed_list = [list() for i in range(NUM_MELT_POOL_CLASSES)]\n",
    "pp_counts = np.zeros(NUM_MELT_POOL_CLASSES)\n",
    "importance_array = np.zeros((NUM_MELT_POOL_CLASSES,NUM_PROCESS_PARAM))\n",
    "\n",
    "for sample in tqdm(dataloader_test): \n",
    "        \n",
    "    R_dict =lrp_eps.evaluate(sample)\n",
    "    \n",
    "    R_img_list = R_dict[\"image\"]\n",
    "    R_img = R_img_list[-1]\n",
    "\n",
    "    R_pp_list = R_dict[\"pp\"]\n",
    "    R_pp = R_pp_list[-1]\n",
    "    \n",
    "#     if np.max(R_pp.detach().cpu().numpy()) > 1:\n",
    "#         img_name = sample['img_name'][0]\n",
    "#         print(R_pp)\n",
    "    \n",
    "    pp = sample['process_parameters'][0]\n",
    "\n",
    "    \n",
    "    images = sample['image']\n",
    "    process_parameters = sample['process_parameters']\n",
    "    images = images.to(device=device, dtype=torch.float)\n",
    "    process_parameters = process_parameters.to(device=device, dtype=torch.float)\n",
    "    with torch.set_grad_enabled(False):\n",
    "        outputs = model(images, process_parameters)\n",
    "        _, preds = torch.max(outputs, 1)\n",
    "        \n",
    "        pp_array[preds,:] += pp.numpy()\n",
    "        pp_counts[preds] += 1\n",
    "        importance_array[preds,:] += R_pp.cpu().numpy()\n",
    "        ed_list[preds].append(pp.numpy()[5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate the average within each melt pool class\n",
    "pp_avg = np.zeros((NUM_MELT_POOL_CLASSES, NUM_PROCESS_PARAM))\n",
    "importance_avg = np.zeros((NUM_MELT_POOL_CLASSES, NUM_PROCESS_PARAM))\n",
    "for ii in range(NUM_MELT_POOL_CLASSES):\n",
    "    pp_avg[ii,:] = pp_array[ii,:] / pp_counts[ii]\n",
    "    importance_avg[ii, :] = importance_array[ii,:] / pp_counts[ii]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the results\n",
    "np.save('LRP_results/pp_avg_test_V30_eps_' + str(EPS), pp_avg)\n",
    "np.save('LRP_results/importance_avg_test_V30_eps_' + str(EPS), importance_avg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the results\n",
    "pp_avg = np.load('LRP_results/pp_avg_test_V30_eps_' + str(EPS) + '.npy')\n",
    "importance_avg = np.load('LRP_results/importance_avg_test_V30_eps_' + str(EPS) + '.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "The number of FixedLocator locations (9), usually from a call to set_ticks, does not match the number of ticklabels (6).",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_24199/1985235831.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      9\u001b[0m     \u001b[0max\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_xticks\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mNUM_PROCESS_PARAM\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m     \u001b[0mpp_labels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m'Power'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'Speed'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'Acceleration'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'Energy Density'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'Heating'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'Residual Heat'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m     \u001b[0max\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_xticklabels\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpp_labels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrotation\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m90\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     12\u001b[0m     \u001b[0max\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_ylabel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Avg. Process Parameter Values\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mcolor\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"blue\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mfontsize\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m14\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m     \u001b[0max\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_ylim\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/multiclassMeltpool/lib/python3.7/site-packages/matplotlib/axes/_base.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m     73\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     74\u001b[0m         \u001b[0;32mdef\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 75\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mget_method\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     76\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     77\u001b[0m         \u001b[0mwrapper\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__module__\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mowner\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__module__\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/multiclassMeltpool/lib/python3.7/site-packages/matplotlib/axis.py\u001b[0m in \u001b[0;36m_set_ticklabels\u001b[0;34m(self, labels, fontdict, minor, **kwargs)\u001b[0m\n\u001b[1;32m   1796\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mfontdict\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1797\u001b[0m             \u001b[0mkwargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfontdict\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1798\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_ticklabels\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlabels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mminor\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mminor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1799\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1800\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_set_tick_locations\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mticks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mminor\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/multiclassMeltpool/lib/python3.7/site-packages/matplotlib/axis.py\u001b[0m in \u001b[0;36mset_ticklabels\u001b[0;34m(self, ticklabels, minor, **kwargs)\u001b[0m\n\u001b[1;32m   1719\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlocator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlocs\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mticklabels\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mticklabels\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1720\u001b[0m                 raise ValueError(\n\u001b[0;32m-> 1721\u001b[0;31m                     \u001b[0;34m\"The number of FixedLocator locations\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1722\u001b[0m                     \u001b[0;34mf\" ({len(locator.locs)}), usually from a call to\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1723\u001b[0m                     \u001b[0;34m\" set_ticks, does not match\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: The number of FixedLocator locations (9), usually from a call to set_ticks, does not match the number of ticklabels (6)."
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 640x480 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Plot the results\n",
    "for ii in range(NUM_MELT_POOL_CLASSES):    \n",
    "    fig, ax = plt.subplots()\n",
    "    ax.scatter(range(NUM_PROCESS_PARAM), pp_avg[ii, :], color=\"blue\")\n",
    "    ax2 = ax.twinx()\n",
    "    \n",
    "    ax2.scatter(range(NUM_PROCESS_PARAM), importance_avg[ii,:], color=\"orange\")\n",
    "    ax2.axhline(0, linestyle='dashed', color=\"orange\")\n",
    "    ax.set_xticks(np.arange(NUM_PROCESS_PARAM))\n",
    "    pp_labels = ('Power','Speed','Acceleration','Energy Density','Heating', 'Residual Heat')\n",
    "    ax.set_xticklabels(pp_labels, rotation=90)\n",
    "    ax.set_ylabel(\"Avg. Process Parameter Values\",color=\"blue\",fontsize=14)\n",
    "    ax.set_ylim([-1, 1])\n",
    "    ax2.set_ylabel(\"Avg. Relevance\",color=\"orange\",fontsize=14)\n",
    "    plt.title('Melt Pool Class ' + str(ii+1))\n",
    "    plt.tight_layout()\n",
    "    plt.savefig('Plots/LRP_plots/V30_eps_' + str(EPS) + '/PP_relevance_class'+str(ii+1)+'_LowRes', dpi=150)\n",
    "#     plt.savefig('Plots/LRP_plots/eps_' + str(EPS) + '/PP_relevance_class'+str(ii+1), dpi=800)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "multiclassMeltpool",
   "language": "python",
   "name": "multiclassmeltpool"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
