{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a0b2a742",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from torchvision import transforms, datasets\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torch.optim import lr_scheduler\n",
    "import os\n",
    "from skimage import io, transform\n",
    "import pandas as pd\n",
    "import time\n",
    "import copy\n",
    "from torchvision.models import resnet18, ResNet18_Weights\n",
    "from PIL import Image\n",
    "from tqdm import tqdm\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a4ccd8f",
   "metadata": {},
   "source": [
    "### Set up the neural network "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4c939dc7",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MeltPoolNetwork(nn.Module):\n",
    "    \"\"\"Neural Network for Melt Pool Shape Prediction\"\"\"\n",
    "    \n",
    "    def __init__(self, imageModel, num_classes=10, num_param=10):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            imageModel (A pytorch model): the CNN to use for melt pool image encoding\n",
    "            num_classes (int): Number of different melt pool classes to predict\n",
    "            num_param (int): Number of process parameters available\n",
    "        \"\"\"\n",
    "        \n",
    "        super().__init__()\n",
    "        # The image encoder CNN\n",
    "        self.ImageModel = imageModel\n",
    "        \n",
    "        # The process parameter encoder layers\n",
    "        self.paramLayer1 = nn.Sequential(nn.Linear(num_param, 10), nn.Tanh())\n",
    "        self.paramLayer2 = nn.Sequential(nn.Linear(10, 10), nn.Tanh())\n",
    "        self.paramLayer3 = nn.Sequential(nn.Linear(10, 10), nn.Tanh())\n",
    "        self.paramLayer4 = nn.Sequential(nn.Linear(10, 10), nn.Tanh())\n",
    "        \n",
    "        # prediction head layers\n",
    "        self.prediction1 = nn.Sequential(nn.Linear(512+10, 100), nn.Tanh())\n",
    "        self.prediction2 = nn.Linear(100, num_classes)\n",
    "\n",
    "        # Initialize Model Weights\n",
    "        tanh_gain = torch.nn.init.calculate_gain('tanh', param=None)\n",
    "        torch.nn.init.xavier_normal_(self.paramLayer1[0].weight, gain=tanh_gain)\n",
    "        torch.nn.init.xavier_normal_(self.paramLayer2[0].weight, gain=tanh_gain)\n",
    "        torch.nn.init.xavier_normal_(self.paramLayer3[0].weight, gain=tanh_gain)\n",
    "        torch.nn.init.xavier_normal_(self.paramLayer4[0].weight, gain=tanh_gain)\n",
    "        torch.nn.init.xavier_normal_(self.prediction1[0].weight, gain=tanh_gain)\n",
    "        torch.nn.init.kaiming_normal_(self.prediction2.weight, a=0, mode='fan_in', nonlinearity='relu')\n",
    "\n",
    "    def forward(self, img, pp):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            img (tensor): The melt pool image\n",
    "            pp  (tensor): The process parameters\n",
    "        \"\"\"\n",
    "        \n",
    "        # Image CNN\n",
    "        x = self.ImageModel(img)\n",
    "\n",
    "        # PP NN\n",
    "        y = self.paramLayer1(pp)\n",
    "        y = self.paramLayer2(y)\n",
    "        y = self.paramLayer3(y)\n",
    "        y = self.paramLayer4(y)\n",
    "        y = y.view(y.size(0), -1)\n",
    "\n",
    "        # Prediction Head\n",
    "        y = torch.squeeze(y)  # remove any dimensions of 1\n",
    "        z = torch.cat((x, y), dim=1)\n",
    "        z = self.prediction1(z)\n",
    "        z = self.prediction2(z)\n",
    "        return z"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "29b7aaae",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MeltPoolNetwork_ImageOnly(nn.Module):\n",
    "    \"\"\"Neural Network for Melt Pool Shape Prediction\"\"\"\n",
    "    \n",
    "    def __init__(self, imageModel, num_classes=10, num_param=10):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            imageModel (A pytorch model): the CNN to use for melt pool image encoding\n",
    "            num_classes (int): Number of different melt pool classes to predict\n",
    "            num_param (int): Number of process parameters available\n",
    "        \"\"\"\n",
    "        \n",
    "        super().__init__()\n",
    "        # The image encoder CNN\n",
    "        self.ImageModel = imageModel\n",
    "\n",
    "    def forward(self, img, pp):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            img (tensor): The melt pool image\n",
    "            pp  (tensor): The process parameters\n",
    "        \"\"\"\n",
    "        \n",
    "        # Image CNN\n",
    "        x = self.ImageModel(img)\n",
    "\n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30cec367",
   "metadata": {},
   "source": [
    "### Set up the dataset/dataloader "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "792a5b3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MeltpoolDataset(Dataset):\n",
    "    \"\"\"Dataset for Meltpool Images and Process Parameters\"\"\"\n",
    "\n",
    "    def __init__(self, xlsx_file, root_dir, transform=None):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            xlsx_file (string): file with process parameters and labels\n",
    "            root_dir (string): image directory\n",
    "            transform (callable, optional): transform(s) to apply\n",
    "        \"\"\"\n",
    "\n",
    "        print('************** Loading Data **************')\n",
    "        print(xlsx_file)\n",
    "        \n",
    "        # Load the excel file and separate into image file names, labels, and process parameters\n",
    "        if xlsx_file.find('xlsx') >= 0:\n",
    "            data_frame = pd.read_excel(xlsx_file, sheet_name='Sheet1', engine='openpyxl')\n",
    "        elif xlsx_file.find('csv')>= 0:\n",
    "            data_frame = pd.read_csv(xlsx_file)\n",
    "        self.images = np.array(data_frame['image_name'])\n",
    "        self.labels = np.array(data_frame['label'])\n",
    "        self.process_parameters = np.array(data_frame[data_frame.columns[2:]])\n",
    "\n",
    "        # We need to modify the image file names\n",
    "        for ii in range(self.images.shape[0]):\n",
    "            layer = self.images[ii][0:self.images[ii].find('_')]\n",
    "            self.images[ii] = layer + '/' + self.images[ii]\n",
    "\n",
    "        # Store some important information\n",
    "        self.root_dir = root_dir\n",
    "        self.transform = transform\n",
    "        self.PIL_transform = transforms.ToPILImage()\n",
    "        print('************ Finished Loading ************')\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.images.shape[0]\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        if torch.is_tensor(idx):\n",
    "            idx = idx.tolist()\n",
    "\n",
    "        # Load the image and convert to a PIL image\n",
    "        img_name = os.path.join(self.root_dir, self.images[idx])\n",
    "        image = io.imread(img_name)\n",
    "        image = self.PIL_transform(image).convert('RGB')\n",
    "        \n",
    "        # Apply transforms to the image\n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "        \n",
    "        # Load the process parameters\n",
    "        pp = self.process_parameters[idx, :]\n",
    "        pp = pp.astype('float')\n",
    "        \n",
    "        # Load the label\n",
    "        label = self.labels[idx]        \n",
    "\n",
    "        return {'image': image, 'process_parameters': pp, 'label': label}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "504895c1",
   "metadata": {},
   "source": [
    "### Set up the training routine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "173da9a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(model, criterion, optimizer, model_name, num_epochs=25, scheduler=None, resume_train=False):\n",
    "    \"\"\"\n",
    "    Args:\n",
    "        model: the neural network model\n",
    "        criterion: The loss function\n",
    "        optimizer: The optimizer used for backprop\n",
    "        model_name (string): name of the model (to save log information to)\n",
    "        num_epochs (int): number of training epochs\n",
    "        scheduler: a scheduler for the learning rate\n",
    "    \"\"\"\n",
    "    if resume_train == False:\n",
    "        with open('log/' + model_name + '.txt', 'w') as f:\n",
    "            f.write('Begin NN Training:\\n\\n')\n",
    "            f.write('Learning rate: ' + str(optimizer.param_groups[-1]['lr']) + '\\n\\n')\n",
    "    else:\n",
    "        with open('log/' + model_name + '.txt', 'a') as f:\n",
    "            f.write('*************************************************\\n')\n",
    "            f.write('Resume NN Training:\\n\\n')\n",
    "            f.write('Learning rate: ' + str(optimizer.param_groups[-1]['lr']) + '\\n\\n')\n",
    "\n",
    "    start_time = time.time()\n",
    "\n",
    "    best_model_wts = copy.deepcopy(model.state_dict())\n",
    "    best_acc = 0.0\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        \n",
    "        epoch_start_time = time.time()\n",
    "        \n",
    "        # Print Epoch Number to terminal\n",
    "        print('Epoch ' + str(epoch) + '/' + str(num_epochs - 1))\n",
    "        print('-' * 10)\n",
    "\n",
    "        # For each epoch, do a run through training set and dev set\n",
    "        for phase in ['train', 'dev']:\n",
    "            if phase == 'train':\n",
    "                model.train()  # Set model to training mode\n",
    "            else:\n",
    "                model.eval()  # Set model to evaluate mode\n",
    "\n",
    "            running_loss = 0.0\n",
    "            running_corrects = 0\n",
    "\n",
    "            # Iterate over data.\n",
    "            for sample in tqdm(dataloaders[phase]):\n",
    "                \n",
    "                # Recover the data from the dictionary\n",
    "                images = sample['image']\n",
    "                process_parameters = sample['process_parameters']\n",
    "                labels = sample['label']\n",
    "\n",
    "                # Send data to device\n",
    "                images = images.to(device=device, dtype=torch.float)\n",
    "                process_parameters = process_parameters.to(device=device, dtype=torch.float)\n",
    "                labels = labels.to(device)\n",
    "\n",
    "                # zero the gradients\n",
    "                optimizer.zero_grad()\n",
    "\n",
    "                # forward pass\n",
    "                with torch.set_grad_enabled(phase == 'train'):\n",
    "                    outputs = model(images, process_parameters)\n",
    "                    _, preds = torch.max(outputs, 1)\n",
    "                    loss = criterion(outputs, labels)\n",
    "\n",
    "                    # backward pass (backprop)\n",
    "                    if phase == 'train':\n",
    "                        loss.backward()\n",
    "                        optimizer.step()\n",
    "\n",
    "                # statistics\n",
    "                running_loss += loss.item() * images.size(0)\n",
    "                running_corrects += torch.sum(preds == labels.data)\n",
    "\n",
    "            if phase == 'train' and scheduler is not None:\n",
    "                scheduler.step()\n",
    "\n",
    "            epoch_loss = running_loss / dataset_sizes[phase]\n",
    "            epoch_acc = running_corrects.double() / dataset_sizes[phase]\n",
    "            \n",
    "            # Print information to terminal\n",
    "            print(f'{phase} Loss: {epoch_loss:.4f} Acc: {epoch_acc:.4f}')\n",
    "            \n",
    "            epoch_elapsed_time = time.time() - epoch_start_time\n",
    "            \n",
    "            # Print information to a log\n",
    "            with open('log/' + model_name + '.txt', 'a') as f:\n",
    "                if phase == 'train':\n",
    "                    f.write('Epoch ' + str(epoch) + '/' + str(num_epochs-1) + '\\n')\n",
    "                    f.write('*************************************************\\n')\n",
    "                f.write(str(phase) + 'Loss: ' + str(epoch_loss) + ' Acc: ' + str(epoch_acc) + '\\n')\n",
    "                f.write('Elapsed Time: ' + str(epoch_elapsed_time) + ' seconds\\n\\n')\n",
    "                if phase == 'dev':\n",
    "                    f.write('*************************************************\\n\\n')\n",
    "\n",
    "            # deep copy the model if best performance on dev set\n",
    "            if phase == 'dev' and epoch_acc > best_acc:\n",
    "                best_acc = epoch_acc\n",
    "                best_model_wts = copy.deepcopy(model.state_dict())\n",
    "\n",
    "        print()\n",
    "\n",
    "    total_time = time.time() - start_time\n",
    "    print(f'Training complete in {total_time // 60:.0f}m {total_time % 60:.0f}s')\n",
    "    print(f'Best dev Acc: {best_acc:4f}')\n",
    "    \n",
    "    with open('log/' + model_name + '.txt', 'a') as f:\n",
    "        f.write('Training Completed in ' + str(total_time) + ' seconds\\n\\n')\n",
    "\n",
    "    # load best model weights\n",
    "    model.load_state_dict(best_model_wts)\n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "246e0da6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_accuracy(model, criterion, model_name):\n",
    "    \"\"\" \n",
    "    Args:\n",
    "        model: The trained model\n",
    "        criterion: The evaluation criteria\n",
    "        model_name: name of the model (to save log information to)\n",
    "    \"\"\"\n",
    "    \n",
    "    # Set to evaluation mode\n",
    "    model.eval()\n",
    "    \n",
    "    running_loss = 0.0\n",
    "    running_corrects = 0\n",
    "    \n",
    "    # No sample through all the data\n",
    "    phase = 'test'\n",
    "    for sample in tqdm(dataloaders[phase]):\n",
    "        images = sample['image']\n",
    "        process_parameters = sample['process_parameters']\n",
    "        labels = sample['label']\n",
    "\n",
    "        # Send data to device\n",
    "        images = images.to(device=device, dtype=torch.float)\n",
    "        process_parameters = process_parameters.to(device=device, dtype=torch.float)\n",
    "        labels = labels.to(device)\n",
    "\n",
    "        # zero the gradients\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # forward pass\n",
    "        with torch.set_grad_enabled(False):\n",
    "            outputs = model(images, process_parameters)\n",
    "            _, preds = torch.max(outputs, 1)\n",
    "            loss = criterion(outputs, labels)\n",
    "\n",
    "        # statistics\n",
    "        running_loss += loss.item() * images.size(0)\n",
    "        running_corrects += torch.sum(preds == labels.data)\n",
    "\n",
    "    epoch_loss = running_loss / dataset_sizes[phase]\n",
    "    epoch_acc = running_corrects.double() / dataset_sizes[phase]\n",
    "    \n",
    "    # Print relevant information to terminal/log file\n",
    "    print(f'{phase} Loss: {epoch_loss:.4f} Acc: {epoch_acc:.4f}')\n",
    "    with open('log/' + model_name + '.txt', 'a') as f:\n",
    "        f.write(str(phase) + 'Loss: ' + str(epoch_loss) + ' Acc: ' + str(epoch_acc) + '\\n\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d277b180",
   "metadata": {},
   "source": [
    "### Load the data, Define the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5d3f3c83",
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 256 # Minibatch size to use\n",
    "NUM_MELT_POOL_CLASSES = 24 # Number of different melt pool shape classes\n",
    "NUM_PROCESS_PARAM = 9 # Number of process parameters\n",
    "NUM_EPOCHS = 10 # Number of epochs to train for\n",
    "LEARNING_RATE = 0.001 # Optimizer learning rate\n",
    "\n",
    "# The base directory to images\n",
    "# DATA_DIR = '../../../In-situ Meas Data/In-situ Meas Data/Melt Pool Camera Preprocessed PNG/'\n",
    "DATA_DIR = '../../Melt Pool Camera Preprocessed PNG/'\n",
    "\n",
    "MODEL_NAME = 'testV5' # Name to save trained model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "19d2f74a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "************** Loading Data **************\n",
      "neural_network_data/train_labels_pp_balanced.csv\n",
      "************ Finished Loading ************\n",
      "************** Loading Data **************\n",
      "neural_network_data/test_labels_pp.csv\n",
      "************ Finished Loading ************\n",
      "************** Loading Data **************\n",
      "neural_network_data/dev_labels_pp.csv\n",
      "************ Finished Loading ************\n"
     ]
    }
   ],
   "source": [
    "#  Load  the datasets\n",
    "\n",
    "# Transforms to apply to images before inputting in neural network\n",
    "image_transforms = {\n",
    "    'train': transforms.Compose([\n",
    "        transforms.RandomResizedCrop(224),\n",
    "        transforms.RandomHorizontalFlip(),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "    ]), \n",
    "    'dev': transforms.Compose([\n",
    "        transforms.Resize(256),\n",
    "        transforms.CenterCrop(224),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "    ]), \n",
    "    'test': transforms.Compose([\n",
    "        transforms.Resize(256),\n",
    "        transforms.CenterCrop(224),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "    ])\n",
    "}\n",
    "\n",
    "\n",
    "# Actually load the data, might take some time\n",
    "meltpool_dataset_train = MeltpoolDataset('neural_network_data/train_labels_pp_balanced.csv', DATA_DIR,\n",
    "                                         transform=image_transforms['train'])\n",
    "meltpool_dataset_test = MeltpoolDataset('neural_network_data/test_labels_pp.csv', DATA_DIR,\n",
    "                                         transform=image_transforms['test'])\n",
    "meltpool_dataset_dev = MeltpoolDataset('neural_network_data/dev_labels_pp.csv', DATA_DIR,\n",
    "                                         transform=image_transforms['dev'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "8d5c57e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataloaders = dict()\n",
    "dataloaders['train'] = DataLoader(meltpool_dataset_train, batch_size=BATCH_SIZE, shuffle=True, num_workers=0)\n",
    "dataloaders['test'] = DataLoader(meltpool_dataset_test, batch_size=BATCH_SIZE, shuffle=True, num_workers=0)\n",
    "dataloaders['dev'] = DataLoader(meltpool_dataset_dev, batch_size=BATCH_SIZE, shuffle=True, num_workers=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "2c0b9faa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The dataset sizes are:\n",
      "{'train': 1868760, 'test': 103104, 'dev': 103081}\n"
     ]
    }
   ],
   "source": [
    "dataset_sizes = dict()\n",
    "dataset_sizes['train'] = len(meltpool_dataset_train)\n",
    "dataset_sizes['test'] = len(meltpool_dataset_test)\n",
    "dataset_sizes['dev'] = len(meltpool_dataset_dev)\n",
    "print('The dataset sizes are:')\n",
    "print(dataset_sizes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ff81fe41",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MeltPoolNetwork(\n",
       "  (ImageModel): ResNet(\n",
       "    (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
       "    (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (relu): ReLU(inplace=True)\n",
       "    (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
       "    (layer1): Sequential(\n",
       "      (0): BasicBlock(\n",
       "        (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (1): BasicBlock(\n",
       "        (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (layer2): Sequential(\n",
       "      (0): BasicBlock(\n",
       "        (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (downsample): Sequential(\n",
       "          (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "          (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "      (1): BasicBlock(\n",
       "        (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (layer3): Sequential(\n",
       "      (0): BasicBlock(\n",
       "        (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (downsample): Sequential(\n",
       "          (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "          (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "      (1): BasicBlock(\n",
       "        (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (layer4): Sequential(\n",
       "      (0): BasicBlock(\n",
       "        (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (downsample): Sequential(\n",
       "          (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "          (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "      (1): BasicBlock(\n",
       "        (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
       "    (fc): Linear(in_features=512, out_features=512, bias=True)\n",
       "  )\n",
       "  (paramLayer1): Sequential(\n",
       "    (0): Linear(in_features=9, out_features=10, bias=True)\n",
       "    (1): Tanh()\n",
       "  )\n",
       "  (paramLayer2): Sequential(\n",
       "    (0): Linear(in_features=10, out_features=10, bias=True)\n",
       "    (1): Tanh()\n",
       "  )\n",
       "  (paramLayer3): Sequential(\n",
       "    (0): Linear(in_features=10, out_features=10, bias=True)\n",
       "    (1): Tanh()\n",
       "  )\n",
       "  (paramLayer4): Sequential(\n",
       "    (0): Linear(in_features=10, out_features=10, bias=True)\n",
       "    (1): Tanh()\n",
       "  )\n",
       "  (prediction1): Sequential(\n",
       "    (0): Linear(in_features=522, out_features=100, bias=True)\n",
       "    (1): Tanh()\n",
       "  )\n",
       "  (prediction2): Linear(in_features=100, out_features=24, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# torch.cuda.empty_cache()\n",
    "\n",
    "ImgModel = resnet18(weights=ResNet18_Weights.IMAGENET1K_V1)\n",
    "ImgModel.fc = nn.Linear(512, 512)\n",
    "ImgModel.to(device)\n",
    "model = MeltPoolNetwork(ImgModel, num_classes=NUM_MELT_POOL_CLASSES, num_param=NUM_PROCESS_PARAM).to(device)\n",
    "\n",
    "model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a563e238",
   "metadata": {},
   "source": [
    "### Load weights (Optional)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "d5e44e64",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model V1 Loaded Successfully, will resume training version 2\n"
     ]
    }
   ],
   "source": [
    "PATH = 'trained_models/' + MODEL_NAME + '.pth'\n",
    "\n",
    "resume_train = False\n",
    "if os.path.isfile(PATH):\n",
    "    i = 1\n",
    "    increasing = True\n",
    "    while increasing:\n",
    "        if os.path.isfile('trained_models/' + MODEL_NAME + '_'  + str(i) + '.pth'):\n",
    "            i += 1\n",
    "        else:\n",
    "            increasing = False\n",
    "            if i != 1:\n",
    "                PATH = 'trained_models/' + MODEL_NAME + '_'  + str(i-1) + '.pth'\n",
    "            i = i-1  \n",
    "        \n",
    "    model.load_state_dict(torch.load(PATH))\n",
    "    model_save_version = str(i+1)\n",
    "    resume_train = True\n",
    "    print(\"Model V\" + str(i) + \" Loaded Successfully, will resume training version \" + model_save_version)\n",
    "else:\n",
    "    print(\"New model, will start training\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76286f33",
   "metadata": {},
   "source": [
    "### Set up optimizer "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "540da818",
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=LEARNING_RATE)\n",
    "# exp_lr_scheduler = lr_scheduler.StepLR(optimizer, step_size=20, gamma=0.1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f6e426c",
   "metadata": {},
   "source": [
    "### Train the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a5b0a8d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0/9\n",
      "----------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|▎                                                                              | 27/7300 [00:25<1:39:05,  1.22it/s]"
     ]
    }
   ],
   "source": [
    "trained_model = train_model(model, criterion, optimizer, MODEL_NAME, num_epochs=NUM_EPOCHS, resume_train=resume_train)\n",
    "test_accuracy(trained_model, criterion, MODEL_NAME)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8f8fc6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# save the trained model\n",
    "if resume_train:\n",
    "    torch.save(trained_model.state_dict(), 'trained_models/' + MODEL_NAME + '_' + model_save_version + '.pth', _use_new_zipfile_serialization=False)\n",
    "else:\n",
    "    torch.save(trained_model.state_dict(), 'trained_models/' + MODEL_NAME + '.pth', _use_new_zipfile_serialization=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc70bb2c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "04c76bf8",
   "metadata": {},
   "source": [
    "### Use only the CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "f600bea7",
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 128 # Minibatch size to use\n",
    "NUM_MELT_POOL_CLASSES = 24 # Number of different melt pool shape classes\n",
    "NUM_PROCESS_PARAM = 9 # Number of process parameters\n",
    "NUM_EPOCHS = 20 # Number of epochs to train for\n",
    "LEARNING_RATE = 0.001 # Optimizer learning rate\n",
    "\n",
    "# The base directory to images\n",
    "# DATA_DIR = '../../../In-situ Meas Data/In-situ Meas Data/Melt Pool Camera Preprocessed PNG/'\n",
    "DATA_DIR = '../../Melt Pool Camera Preprocessed PNG/'\n",
    "\n",
    "MODEL_NAME = 'testV1_image_only' # Name to save trained model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "972d2c90",
   "metadata": {},
   "outputs": [],
   "source": [
    "ImgModel = resnet18(weights=ResNet18_Weights.IMAGENET1K_V1)\n",
    "ImgModel.fc = nn.Linear(512, NUM_MELT_POOL_CLASSES)\n",
    "ImgModel.to(device)\n",
    "model = MeltPoolNetwork_ImageOnly(ImgModel, num_classes=NUM_MELT_POOL_CLASSES, num_param=NUM_PROCESS_PARAM).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "6613a86b",
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=LEARNING_RATE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08bd1585",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0/19\n",
      "----------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 6444/6444 [43:23<00:00,  2.47it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train Loss: 0.4863 Acc: 0.8453\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 806/806 [03:25<00:00,  3.92it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dev Loss: 0.9852 Acc: 0.6942\n",
      "\n",
      "Epoch 1/19\n",
      "----------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 14%|██████████████████                                                                                                              | 911/6444 [06:07<37:03,  2.49it/s]"
     ]
    }
   ],
   "source": [
    "trained_model = train_model(model, criterion, optimizer, MODEL_NAME, num_epochs=NUM_EPOCHS, resume_train=resume_train)\n",
    "test_accuracy(trained_model, criterion, MODEL_NAME)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "0078c357",
   "metadata": {},
   "outputs": [],
   "source": [
    "# save the trained model\n",
    "torch.save(trained_model.state_dict(), 'trained_models/' + MODEL_NAME + '.pth', _use_new_zipfile_serialization=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "468e2e73",
   "metadata": {},
   "source": [
    "### Produce the Confusion Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d172ef46",
   "metadata": {},
   "outputs": [],
   "source": [
    "PATH = 'trained_models/' + MODEL_NAME + '.pth'\n",
    "\n",
    "resume_train = False\n",
    "if os.path.isfile(PATH):\n",
    "    i = 1\n",
    "    increasing = True\n",
    "    while increasing:\n",
    "        if os.path.isfile('trained_models/' + MODEL_NAME + '_'  + str(i) + '.pth'):\n",
    "            i += 1\n",
    "        else:\n",
    "            increasing = False\n",
    "            if i != 1:\n",
    "                PATH = 'trained_models/' + MODEL_NAME + '_'  + str(i-1) + '.pth'\n",
    "            i = i-1  \n",
    "        \n",
    "    model.load_state_dict(torch.load(PATH))\n",
    "    model_save_version = str(i+1)\n",
    "    resume_train = True\n",
    "    print(\"Model V\" + str(i) + \" Loaded Successfully\" + model_save_version)\n",
    "else:\n",
    "    print(\"Model Not Found\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b34f00ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute values needed for confusion matrix\n",
    "num_images = dataset_sizes['test']\n",
    "ground_truth = np.zeros((num_images,1))\n",
    "predicted = np.zeros((num_images,1))\n",
    "\n",
    "index = 0\n",
    "for sample in tqdm(dataloaders['test']):\n",
    "    images = sample['image']\n",
    "    process_parameters = sample['process_parameters']\n",
    "    labels = sample['label']\n",
    "\n",
    "    # Send data to device\n",
    "    images = images.to(device=device, dtype=torch.float)\n",
    "    process_parameters = process_parameters.to(device=device, dtype=torch.float)\n",
    "    labels = labels.to(device)\n",
    "    \n",
    "    outputs = model(images, process_parameters)\n",
    "    _, preds = torch.max(outputs, 1)\n",
    "    \n",
    "    if index+BATCH_SIZE <= num_images:\n",
    "        ground_truth[index:index+BATCH_SIZE,0] = labels.cpu()\n",
    "        predicted[index:index+BATCH_SIZE,0] = preds.cpu()\n",
    "        index = index + BATCH_SIZE\n",
    "    else:\n",
    "        ground_truth[index:,0] = labels.cpu()\n",
    "        predicted[index:,0] = preds.cpu()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aee1a2a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# compute the confusion matrix\n",
    "confusion_matrix = sklearn.metrics.confusion_matrix(ground_truth, predicted, normalize=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c45871c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the confusion matrix\n",
    "disp = sklearn.metrics.ConfusionMatrixDisplay.from_predictions(ground_truth, predicted, include_values=False,\n",
    "                                                              normalize='true', display_labels=range(1,NUM_MELT_POOL_CLASSES+1),\n",
    "                                                              xticks_rotation='vertical')\n",
    "plt.title('Melt Pool Classifier Confusion Matrix')\n",
    "# plt.savefig('Plots/ConfusionMatrix_LowRes.png', dpi=150)\n",
    "# plt.savefig('Plots/ConfusionMatrix.png', dpi=600)\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "multiclassMeltpool",
   "language": "python",
   "name": "multiclassmeltpool"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
